[{"path":"index.html","id":"about-masmr","chapter":"1 About masmr","heading":"1 About masmr","text":"book provides introduction masmr: Modular Algorithms Spotcalling MERFISH R.{masmr} package designed allow users build custom image processing pipelines, focus MERFISH decoding.","code":""},{"path":"index.html","id":"installation","chapter":"1 About masmr","heading":"1.1 Installation","text":"Currently, package hosted GitHub:https://github.com/eugenekwaNeuromics/masmr/.Installation achievable devtools package:Currently depends following packages:ggplot2, scales, reshape2, viridis: plotting.data.table: quick reading writing data files.RBioFormats: reading variety microscopy image formats.imager, EBImage: image processing functions.tripack: triangular meshing functions.reticulate: interfacing Python (used cell segmentation).parallel: getting number cores machine.Rcpp, RcppEigen: functions written C++.RcppML: fast non-negative matrix factorization.igraph: clustering.rlang: parsing arguments.","code":"\ndevtools::install_github('eugenekwaNeuromics/masmr')"},{"path":"introduction.html","id":"introduction","chapter":"2 Introduction","heading":"2 Introduction","text":"","code":""},{"path":"introduction.html","id":"why-do-you-need-masmr","chapter":"2 Introduction","heading":"2.1 Why do you need {masmr}?","text":"Existing MERFISH decoding workflows typically designed “plug play”: requiring minimal manual adjustment re-parameterisation. one-size-fits-approaches work well assumptions data hold true, return dramatically reduced performance erroneous decoding .{masmr} thus designed wanted control MERFISH decoding, beyond offered existing software. package also designed intuitive syntax, users can adapt software without needing deep technical expertise. also provide numerous plots quality check (QC) metrics help users design pipelines.technically designed focus MERFISH, image processing fundamentals introduced {masmr} can applied many data sets contexts. thus hope {masmr} (accompanying book) can serve user-friendly teaching tool; especially -served community R coders seeking analyse image data.","code":""},{"path":"introduction.html","id":"background","chapter":"2 Introduction","heading":"2.2 Background","text":"MERFISH pipelines, one wants accomplish following tasks:Spotcalling: involves reading fluorescence image, performing necessary image processing steps, decoding, returning spot coordinates. typically performed one image / field--view (FOV) time. Ideally, users optimise spotcalling pipeline one FOV looping FOVs, applying spotcalling criteria.Spotcalling: involves reading fluorescence image, performing necessary image processing steps, decoding, returning spot coordinates. typically performed one image / field--view (FOV) time. Ideally, users optimise spotcalling pipeline one FOV looping FOVs, applying spotcalling criteria.Cell segmentation: Cell segmentation involves identifying nuclei cells image recording locations cell mask. , typically performed one FOV time.Cell segmentation: Cell segmentation involves identifying nuclei cells image recording locations cell mask. , typically performed one FOV time.Stitching: Stitching involves alignment partially overlapping FOVs, coherent image coordinate system obtained.Stitching: Stitching involves alignment partially overlapping FOVs, coherent image coordinate system obtained.Synthesis: processed every FOV, final step consolidate outputs easy--read format. Care must taken ensure coordinate information comparable spots cell masks, spots assigned correct cells.Synthesis: processed every FOV, final step consolidate outputs easy--read format. Care must taken ensure coordinate information comparable spots cell masks, spots assigned correct cells.recommended tasks accomplished separate scripts. Furthermore, time-saving possible performing tasks (1), (2), (3) parallel, consolidation step (4).","code":""},{"path":"introduction.html","id":"quick-start-scripts","chapter":"2 Introduction","heading":"2.3 Quick start scripts","text":", provide several quick start scripts users wish immediately proceed default MERFISH pipeline. Details step provided subsequent chapters.Spotcalling Cell segmentation scripts can run parallel save time. Stitching can also run alongside Spotcalling Cell segmentation, previous two scripts. Finally, Synthesis script run consolidate outputs previous three scripts.3D image stacks, default processing perform maximum intensity projection. users may simply loop Z plane wish. Kindly refer Troubleshooting (Chapter 8) details.","code":""},{"path":"introduction.html","id":"quick-start-spotcalling","chapter":"2 Introduction","heading":"2.3.1 Quick start: Spotcalling","text":"Spotcalling script, loop FOVs, performing default image processing (getImageMetrics). Processed images registered reference image (registerImages) pixels spots maximally overlapped. Information FOV consolidated dataframe (consolidateImageMetrics) pixels rows metrics (e.g. pixel intensity per image) columns. Pixels assigned identity decoding (decode). dataframe successively filtered series recommended filters; users may add / drop filters needed.Per FOV, final output dataframe containing spot locations rows (single pixel per spot), accumulated meta data columns.","code":"\n## If runnning into Java Heap Issues try increasing your memory \n## This needs to be done in a fresh R session: .rs.restartR()\noptions(java.parameters = \"-Xmx16g\") #16Gb (which may be overkill)\nlibrary(rJava)\n.jinit()\ncat(paste0('Available memory: ', .jcall(.jnew(\"java/lang/Runtime\"), \"J\", \"maxMemory\") / 1e9, ' Gb...'))\n\nlibrary(masmr)\n\n## Preparation ahead of looping through FOVs\nestablishParams( ... , verbose = T ) #User to input. Verbose = T returns messages keeping track of progress.\nreadImageMetaData()\nprepareCodebook()\ngetAnchorParams()\nestablishCleanSlate()\n\n## Alternatively, users can keep verbose = T but send output to messages.Rout\n# notVerbose = F\n# if( notVerbose ){\n#   outMessageFile <- file( paste0(params$out_dir, 'messages.Rout'), open = 'wt' )\n#   sink(outMessageFile, type = 'message')\n#   message(\"\\nRedirecting messages to messages.Rout...\\n\\n\")\n# }\n\n## Start loop\nfor( fovName in params$fov_names ){\n  \n  ## Report current FOV / iteration \n  message( paste0(\n    '\\n', fovName, ': ', \n    which(params$fov_names==fovName), ' of ', \n    length(params$fov_names), '...' ) )\n  \n  ## Check if file has been created, skip if yes\n  if( params$resumeMode ){\n    checkFile <- file.exists( paste0(params$out_dir, 'SPOTCALL_', fovName, '.csv.gz') )\n    if(checkFile){\n      message('FOV has been processed...Skipping...')\n      next\n    }\n  }\n  \n  ## Keep track of the current_fov\n  params$current_fov <- fovName\n  \n  ## Load current FOV images\n  imList <- readImageList( params$current_fov )\n  \n  ## If a Z-stack, maximum intensity projection\n  imList <- maxIntensityProject( imList )\n  \n  ## Check if image is largely empty, if so, skip\n  percBlank <- mean( sapply(1:length(imList), function(i){\n    sum( imList[[i]] < params$brightness_min[i] ) / length(imList[[i]])\n  }) )\n  if( percBlank >= 0.95 ){ next }\n  \n  ## Get image metrics\n  getImageMetrics( imList )\n  \n  ## Register\n  forReg <- list()\n  for(i in 1:length(imList)){\n    forReg[[i]] <- imNormalise( imMetrics$COARSE[[i]] + imMetrics$DECODE[[i]] )\n  }\n  names(forReg) <- names(imList)\n  registerImages(forReg)\n  \n  ## Consolidate into pixel wise metric dataframe\n  spotcalldf <- consolidateImageMetrics()\n  cleanUp( c('spotcalldf', cleanSlate) )\n  \n  ## Decode and annotate blanks\n  spotcalldf <- decode(spotcalldf)\n  spotcalldf$BLANK <- scoreBlanks( spotcalldf ) >0\n  \n  ## Binarise and threshold on Hamming distance\n  spotcalldf <- bitsFromDecode(spotcalldf, trainIndex = !spotcalldf$BLANK)\n  spotcalldf <- filterDF(spotcalldf, spotcalldf$HD>1)\n  \n  ## Distance-based filtering\n  filtout <- rep(0, nrow(spotcalldf))\n  for( distanceMetric in c('COS', 'EUC', 'L2E') ){\n    thresh <- thresh_Quantile( \n      spotcalldf[,distanceMetric], \n      label = spotcalldf$BLANK, \n      quantileFalse = 0.5, quantileTrue = 0.5 )\n    filtout <- filtout + spotcalldf[,distanceMetric] > thresh\n  }\n  spotcalldf <- filterDF(spotcalldf, filtout>0)\n  \n  ## Filter nonblanks that are next to blanks\n  spotcalldf$NEXTTOBLANK <- spatialIsAdjacent( spotcalldf, 'BLANK' )\n  spotcalldf <- filterDF(spotcalldf, spotcalldf$NEXTTOBLANK & !spotcalldf$BLANK)\n \n  ## Filter using DFF0 metrics\n  spotcalldf <- scoreDeltaF( spotcalldf )\n  thresh <- thresh_Quantile( \n    spotcalldf[,'DFF0_DECODE'], \n    label = spotcalldf$BLANK, \n    quantileFalse = 0.25, quantileTrue = 0.25 )\n  spotcalldf <- filterDF(spotcalldf, spotcalldf[,'DFF0_DECODE'] < thresh & spotcalldf$F0_DECODE!=0)\n  \n  ## Filter based on HNN distance\n  spotcalldf$HNNDIST <- spatialHNNDist( spotcalldf )\n  spotcalldf <- filterDF( spotcalldf, spotcalldf$HNNDIST > 5 | is.na(spotcalldf$HNNDIST) )\n  \n  ## Filter based on PBLANK  \n  forExclusion <- c('Xm', 'Ym', 'fov', 'g', 'WX', 'WY', 'IDX', \n                    colnames(spotcalldf)[grepl('_\\\\d+$|^DFF0_|^F1_|CV_|LAB$', colnames(spotcalldf))])\n  spotcalldf$PBLANK <- scoreClassifier(spotcalldf, 'BLANK', variablesExcluded = forExclusion)\n  thresh <- thresh_Quantile(spotcalldf$PBLANK, spotcalldf$BLANK, quantileFalse = 0.5, quantileTrue = 0.25)\n  spotcalldf <- filterDF(spotcalldf, spotcalldf$PBLANK > thresh)\n  \n  ## Cluster\n  clusterInfo <- spatialClusterLeiden( spotcalldf, minNeighbours = 3, maxInterSpotDistancePixels = 3)\n  spotcalldf[,colnames(clusterInfo)] <- clusterInfo\n  maxClusterSize = 250\n  spotcalldf <- filterDF(spotcalldf, !(spotcalldf$CENTROID & spotcalldf$CLUSTER_SIZE < maxClusterSize) )\n  saveDF( spotcalldf )\n  \n  cleanUp()\n}"},{"path":"introduction.html","id":"quick-start-cell-segmentation","chapter":"2 Introduction","heading":"2.3.2 Quick start: Cell segmentation","text":"Cell segmentation loops DAPI images. default model specified establishCellSegModel cellpose (nuclei model).Per FOV, final output dataframe pixels rows cell mask assigned pixel.","code":"\nlibrary(masmr)\n\n## Preparation ahead of looping through FOVs\nestablishParams( ... , verbose = T ) #User to input\nreadImageMetaData( 'dapi_dir' ) #Switch to DAPI images and prepare meta data\nestablishCellSegModel()\nestablishCleanSlate()\n\n## Start loop\nfor( fovName in params$fov_names ){\n  \n  ## Report current FOV / iteration \n  message( paste0(\n    '\\n', fovName, ': ', \n    which(params$fov_names==fovName), ' of ', \n    length(params$fov_names), '...' ) )\n  \n  ## Check if file has been created, skip if yes\n  if( params$resumeMode ){\n    checkFile <- file.exists( \n      paste0(params$out_dir, 'CELLSEG_',\n             paste(sort(ls(cellSeg)), collapse=''), '_', \n             fovName, '.csv.gz') )\n    if(checkFile){\n      message('FOV has been processed...Skipping...')\n      next\n    }\n  }\n  \n  ## Keep track of the current_fov\n  params$current_fov <- fovName\n  \n  ## Load current FOV image\n  im <- readImageList( params$current_fov )[[1]] #List of 1\n  \n  ## Cell segmentation and saving\n  cellMask <- runCellSegModel(im)\n  saveCellSegMasks(cellMask, im = im)\n  \n  cleanUp()\n}"},{"path":"introduction.html","id":"quick-start-stitching","chapter":"2 Introduction","heading":"2.3.3 Quick start: Stitching","text":"Stitching script identifies necessary rigid transformation required adjacent FOVs overlap appropriately.Per FOV, final output dataframe neighbouring FOVs rows, vectors needed moving FOVs maximise overlap reference FOV. Two vectors returned script – one stitching MERFISH images, one stitching DAPI images – one required.","code":"\nlibrary(masmr)\n\n## Preparation ahead of looping through FOVs\nestablishParams( ... , verbose = T ) #User to input\nestablishCleanSlate()\n\n## Start loop\nfor( fovName in params$fov_names ){\n  \n  ## Report current FOV / iteration \n  message( paste0(\n    '\\n', fovName, ': ', \n    which(params$fov_names==fovName), ' of ', \n    length(params$fov_names), '...' ) )\n  \n  ## Check if file has been created, skip if yes\n  if( params$resumeMode ){\n    checkFile <- file.exists( paste0(params$out_dir, 'STITCH_', fovName, '.csv') )\n    if(checkFile){\n      cat('FOV has been processed...Skipping...')\n      next\n    }\n  }\n  \n  ## Keep track of the current_fov\n  params$current_fov <- fovName\n  \n  ## Stitch with respect to reference bit\n  imList <- readImagesForStitch( subDirectory = 'IM', loadProcessedImages =  T ) #Assume spotcalling done\n  stitchResults <- stitchImages( imList )\n  \n  ## Optional: Stitch with respect to DAPI image\n  df <- stitchResults\n  colnames(df)[2] <- paste0('merfish_', colnames(stitchResults)[2]) #Save the stitch results from merfish in its own column\n  imList <- readImagesForStitch( subDirectory = 'DAPI', loadProcessedImages =  T ) #Assume cell segmentation done\n  stitchResults <- stitchImages( imList )\n  \n  ## Optional: If have both merfish and cell segmentation stich vectors, consolidate into a single dataframe\n  colnames(stitchResults)[2] <- paste0('dapi_', colnames(stitchResults)[2])\n  stitchResults[,colnames(df)[2]] <- df[match(stitchResults[,1], df[,1]),2]\n  \n  ## Save stitch dataframe\n  saveStitch( stitchResults )\n  \n  cleanUp()\n}"},{"path":"introduction.html","id":"quick-start-synthesis","chapter":"2 Introduction","heading":"2.3.4 Quick start: Synthesis","text":"last script. Synthesis combines outputs previous three scripts series dataframes, across every processed FOV. Additionally, users can plotQC return default QC plots evaluate pipeline’s performance.Hereafter, users wish save space, can delete intermediate results returned previous three scripts.","code":"\nlibrary(masmr)\n\n## Establish params\nestablishParams( ... , verbose = T ) #User to input\n\n## Function to synthesise data\nsynthesizeData()\n\n## Function to generate QC plots\nplotQC()"},{"path":"spotcalling.html","id":"spotcalling","chapter":"3 Spotcalling","heading":"3 Spotcalling","text":"MERFISH data comprises fluorescent images across different channels imaging cycles. desired end result spot coordinates spot identities.end, need perform several subtasks: (1) establish parameters parse necessary metadata, (2) load process relevant images, (3) consolidate information across images decode intensity vectors using MERFISH codebook, (3) filter low quality spots, finally (4) save output. Subtasks 2-4 repeatedly performed loop FOVs.","code":"\nlibrary(masmr)\nlibrary(ggplot2)"},{"path":"spotcalling.html","id":"pre-processing","chapter":"3 Spotcalling","heading":"3.1 Pre-processing","text":"running pipeline proper, series pre-processing steps script needs perform. explained detail , principles apply cell segmentation consolidation scripts.","code":""},{"path":"spotcalling.html","id":"establishing-parameters","chapter":"3 Spotcalling","heading":"3.1.1 Establishing parameters","text":"scripts begin establishing parameters: e.g. location files read, location output files, file formats etc.accomplished masmr using establishParams() function, automatically creates environment object called params global environment repeatedly referenced downstream functions.bare minimum, users need establish:imageDirs: MERFISH image files located.imageFormat: image file formats read. Typically .ome.tif .dax, formats compatible Bioformats acceptable .codebookFileName: location MERFISH codebook.codebookColumnNames: names every bit MERFISH codebook. “bit name” typically comprise image index (e.g. image 1, 2, 3 etc) channel (e.g. Cy3, Alexa-594 etc): bit titled 0_cy3 tells us image loaded Cy3 channel first image set (, starting 0). important order images loaded may match order bits codebook.outDir: output files written .parameters dapiDir pythonLocation discussed subsequently Cell Segmentation.also exist parameters fpkmFileName (file containing FPKM data) nProbesFileName (file containing number MERFISH encoding probes per gene), files read quality control purposes. However, parameters designed optional, code run fine even specified.information stored params object can read details:Note existence params$resumeMode object. houses boolean determines functions skipped evidence run . default, save time, set TRUE.WARNING!troubleshooting, advised resume mode turned intermediate files can overwritten (otherwise, pipeline resume intermediate files). Alternatively, users can leave resume mode go output directory manually delete files wish overwrite.","code":"\ndata_dir = 'C:/Users/kwaje/Downloads/JIN_SIM/20190718_WK_T2_a_B2_R8_12_d50/'\nestablishParams(\n  \n  ## User to fill in\n  imageDirs = paste0(data_dir, 'S10/'), # Where your images are\n  imageFormat = '.ome.tif', # What format your images are in\n  outDir = 'C:/Users/kwaje/Downloads/JYOUT/', # Where to send output to\n  codebookFileName = list.files(paste0(data_dir,'codebook/'),pattern='codebook',full.names = TRUE), # Filename and location of your codebook\n  dapiDir = paste0(data_dir, 'DAPI_1/'), # Where DAPI images are\n  \n  ## Will attempt automatic fill\n  metaFormat = '.ome.tif', # Depends on imageFormat: assumd \n  dapiFormat = '.ome.tif', # Assumed to be the same as imageFormat above (but written it out here explicitly)\n  codebookColumnNames = paste0(rep(c(0:3),4),'_',rep(c('cy3','alexa594','cy5','cy7'),each=4)), #If not provided, will attempt placeholder names\n  pythonLocation = 'C:/Users/kwaje/AppData/Local/miniforge3/envs/scipyenv/', #If unspecified, defaults to reticulate::miniconda_path()\n  \n  ## Automatically filled\n  seed = 12345, # The default seed is 12345\n  verbose = FALSE, # It is generally a good idea to keep verbose as True, but will turn it off for this showcase\n  resumeMode = TRUE, # Set this to FALSE if troubleshooting, to overwrite existing files. TRUE for resuming from last checkpoint. \n  \n  ## Optional (but recommended for QC checks)\n  fpkmFileName = paste0(data_dir, \"FPKM_data/Jin_FPKMData_B.tsv\"),\n  nProbesFileName = paste0(data_dir, \"ProbesPerGene.csv\")\n)\nls( envir = params )##  [1] \"codebook_colnames\"         \"codebook_file\"             \"dapi_dir\"                  \"dapi_format\"               \"dir_names\"                \n##  [6] \"fov_names\"                 \"fpkm_file\"                 \"im_dir\"                    \"im_format\"                 \"inferred_codebookColnames\"\n## [11] \"meta_format\"               \"n_probes_file\"             \"nbits\"                     \"out_dir\"                   \"parent_out_dir\"           \n## [16] \"python_location\"           \"raw_codebook\"              \"resumeMode\"                \"seed\"                      \"verbose\""},{"path":"spotcalling.html","id":"getting-parameters-from-image-metadata","chapter":"3 Spotcalling","heading":"3.1.2 Getting parameters from image metadata","text":"next step obtain image metadata accompanies microscopy images. typically found file image data (e.g. .ome.tif) can sometimes separate file (e.g. .xml accompany .dax images). masmr attempt guess meta data format appropriate, users can change values params needed.can check values entered params:unsatisfied, can update follows:specified meta data formats, can load additional meta data information readImageMetaData function.adds additional information params, resolution information:also creates dataframe stores file information every bit. referenced heavily downstream functions.Note default, information saved sub-directory chosen output folder.","code":"\nparams$meta_format## [1] \".ome.tif\"\nparams$meta_format <- '.dax'\nprint(params$meta_format)## [1] \".dax\"\nparams$meta_format <- '.ome.tif'\nprint(params$meta_format)## [1] \".ome.tif\"\nreadImageMetaData()## Warning in readImageMetaData(): Assuming this data has been acquired by Triton## Warning in readImageMetaData(): Updating params$fov_names\nprint( params$resolutions )## $per_pixel_microns\n## [1] \"0.0706\" \"0.0706\"\n## \n## $xydimensions_pixels\n## [1] \"2960\" \"2960\"\n## \n## $xydimensions_microns\n## [1] \"208.976\" \"208.976\"\n## \n## $channel_order\n## [1] \"cy7\"      \"cy5\"      \"alexa594\" \"cy3\"     \n## \n## $fov_names\n##   [1] \"MMStack_1-Pos_000_000\" \"MMStack_1-Pos_001_000\" \"MMStack_1-Pos_002_000\" \"MMStack_1-Pos_003_000\" \"MMStack_1-Pos_004_000\" \"MMStack_1-Pos_005_000\"\n##   [7] \"MMStack_1-Pos_006_000\" \"MMStack_1-Pos_007_000\" \"MMStack_1-Pos_008_000\" \"MMStack_1-Pos_009_000\" \"MMStack_1-Pos_009_001\" \"MMStack_1-Pos_008_001\"\n##  [13] \"MMStack_1-Pos_007_001\" \"MMStack_1-Pos_006_001\" \"MMStack_1-Pos_005_001\" \"MMStack_1-Pos_004_001\" \"MMStack_1-Pos_003_001\" \"MMStack_1-Pos_002_001\"\n##  [19] \"MMStack_1-Pos_001_001\" \"MMStack_1-Pos_000_001\" \"MMStack_1-Pos_000_002\" \"MMStack_1-Pos_001_002\" \"MMStack_1-Pos_002_002\" \"MMStack_1-Pos_003_002\"\n##  [25] \"MMStack_1-Pos_004_002\" \"MMStack_1-Pos_005_002\" \"MMStack_1-Pos_006_002\" \"MMStack_1-Pos_007_002\" \"MMStack_1-Pos_008_002\" \"MMStack_1-Pos_009_002\"\n##  [31] \"MMStack_1-Pos_009_003\" \"MMStack_1-Pos_008_003\" \"MMStack_1-Pos_007_003\" \"MMStack_1-Pos_006_003\" \"MMStack_1-Pos_005_003\" \"MMStack_1-Pos_004_003\"\n##  [37] \"MMStack_1-Pos_003_003\" \"MMStack_1-Pos_002_003\" \"MMStack_1-Pos_001_003\" \"MMStack_1-Pos_000_003\" \"MMStack_1-Pos_000_004\" \"MMStack_1-Pos_001_004\"\n##  [43] \"MMStack_1-Pos_002_004\" \"MMStack_1-Pos_003_004\" \"MMStack_1-Pos_004_004\" \"MMStack_1-Pos_005_004\" \"MMStack_1-Pos_006_004\" \"MMStack_1-Pos_007_004\"\n##  [49] \"MMStack_1-Pos_008_004\" \"MMStack_1-Pos_009_004\" \"MMStack_1-Pos_009_005\" \"MMStack_1-Pos_008_005\" \"MMStack_1-Pos_007_005\" \"MMStack_1-Pos_006_005\"\n##  [55] \"MMStack_1-Pos_005_005\" \"MMStack_1-Pos_004_005\" \"MMStack_1-Pos_003_005\" \"MMStack_1-Pos_002_005\" \"MMStack_1-Pos_001_005\" \"MMStack_1-Pos_000_005\"\n##  [61] \"MMStack_1-Pos_000_006\" \"MMStack_1-Pos_001_006\" \"MMStack_1-Pos_002_006\" \"MMStack_1-Pos_003_006\" \"MMStack_1-Pos_004_006\" \"MMStack_1-Pos_005_006\"\n##  [67] \"MMStack_1-Pos_006_006\" \"MMStack_1-Pos_007_006\" \"MMStack_1-Pos_008_006\" \"MMStack_1-Pos_009_006\" \"MMStack_1-Pos_009_007\" \"MMStack_1-Pos_008_007\"\n##  [73] \"MMStack_1-Pos_007_007\" \"MMStack_1-Pos_006_007\" \"MMStack_1-Pos_005_007\" \"MMStack_1-Pos_004_007\" \"MMStack_1-Pos_003_007\" \"MMStack_1-Pos_002_007\"\n##  [79] \"MMStack_1-Pos_001_007\" \"MMStack_1-Pos_000_007\" \"MMStack_1-Pos_000_008\" \"MMStack_1-Pos_001_008\" \"MMStack_1-Pos_002_008\" \"MMStack_1-Pos_003_008\"\n##  [85] \"MMStack_1-Pos_004_008\" \"MMStack_1-Pos_005_008\" \"MMStack_1-Pos_006_008\" \"MMStack_1-Pos_007_008\" \"MMStack_1-Pos_008_008\" \"MMStack_1-Pos_009_008\"\n##  [91] \"MMStack_1-Pos_009_009\" \"MMStack_1-Pos_008_009\" \"MMStack_1-Pos_007_009\" \"MMStack_1-Pos_006_009\" \"MMStack_1-Pos_005_009\" \"MMStack_1-Pos_004_009\"\n##  [97] \"MMStack_1-Pos_003_009\" \"MMStack_1-Pos_002_009\" \"MMStack_1-Pos_001_009\" \"MMStack_1-Pos_000_009\"\n## \n## $zslices\n## [1] \"1\"\nknitr::kable( head( params$global_coords ), format = 'html', booktabs = TRUE )\nprint( params$parent_out_dir )## [1] \"C:/Users/kwaje/Downloads/JYOUT/\"\nprint( params$out_dir )## [1] \"C:/Users/kwaje/Downloads/JYOUT//IM/\""},{"path":"spotcalling.html","id":"preparing-the-codebook","chapter":"3 Spotcalling","heading":"3.1.3 Preparing the codebook","text":"codebook table indicating sequence (1) (0) bits gene (example ). {masmr} expects table (e.g. .csv .txt) contains N rows N genes/blanks, M+1 columns M bits (e.g. 16-bit setup) 1 gene column.Unique spotcalling, users must “prepare” codebooks. typically involves ensuring order bits matches order image loading masmr performs. Additionally, masmr also provides option add “blanks” beyond already specified user.new ordered codebook stored output directory, users can refer follows:","code":"\nknitr::kable( head(data.table::fread( params$codebook_file, data.table = F )), format = 'html', booktabs = TRUE )\nprepareCodebook( exhaustiveBlanks = T )\nknitr::kable( head( params$ordered_codebook ), format = 'html', booktabs = TRUE )"},{"path":"spotcalling.html","id":"house-keeping","chapter":"3 Spotcalling","heading":"3.1.4 House-keeping","text":"performed necessary pre-processing, may useful users take snapshot current environment. Unnecessary data can cleared memory subsequent steps return global environment snapshot. accomplished using establishCleanSlate cleanUp functions.example use-case provided :","code":"\nestablishCleanSlate()## [1] \".Random.seed\" \"data_dir\"     \"full_res\"     \"n_channels\"   \"params\"\nprint(cleanSlate)## [1] \".Random.seed\" \"data_dir\"     \"full_res\"     \"n_channels\"   \"params\"       \"cleanSlate\"\nx = '12345'\nexists('x')## [1] TRUE\ncleanUp()\nexists('x')## [1] FALSE"},{"path":"spotcalling.html","id":"preparing-to-loop-through-images","chapter":"3 Spotcalling","heading":"3.2 Preparing to loop through images","text":"done necessary pre-processing, users may now begin processing FOV. done looping params$fov_names. also recommended current FOV saved params$current_fov.Users may also wish check ready loop checkReadyLoop function, entirely optional.","code":"\nhead(params$fov_names)## [1] \"MMStack_1-Pos_000_000\" \"MMStack_1-Pos_001_000\" \"MMStack_1-Pos_002_000\" \"MMStack_1-Pos_003_000\" \"MMStack_1-Pos_004_000\" \"MMStack_1-Pos_005_000\"\nparams$current_fov <- params$fov_names[38]\nprint(params$current_fov)## [1] \"MMStack_1-Pos_002_003\"\ncheckReadyLoop()## Warning in checkReadyLoop(): params$brightness_min not found:\n##       If desired, ensure getAnchorParams() has been run## [1] FALSE"},{"path":"spotcalling.html","id":"image-reading","chapter":"3 Spotcalling","heading":"3.2.1 Image reading","text":"read images, rely RBioformats package, able read image file formats. One exception .dax files – however, binary files can read base R. account different types images, can use readImage function masmr., provide example .dax file:, note default imageDimensions assumed : Number Channels, Number rows, Number Columns, Number Z slices. case, since nchannels nzs 1, users technically specify image dimensions using width height alone. However, generally good practice keep consistent format..ome.tif files, function can used. However, need specify additional series parameter: otherwise, FOVs loaded. details, recommend reading documentation RBioformats::read.image. , provide example reading second channel current FOV (specified ).Note readImage written reads four channels memory, subset second channel using im[,,2]. alternative just load second channel directly using subset parameter RBioformats::read.image, channelIndex parameter readImage. useful memory management.MERFISH, typically handle multiple images . thus created additional image reading function called readImageList loads images given FOV, cross-referencing params$global_coords find relevant files. readImageList cross-referencing, parameters nchannels, nzs etc specified.","code":"\nfile <- 'C:/Users/kwaje/Downloads/LIU_CONNECT_CORTICALORGANOID_240902/DATA/20240902/cont/Alexa594_0_10.dax'\nim <- readImage( \n  file,\n  imageDimensions = c(1,2048,2048,1),\n  nchannels = 1, #The image only has 1 channel\n  nzs = 1\n  )## Warning in readImage(file, imageDimensions = c(1, 2048, 2048, 1), nchannels = 1, : Unable to read with RBioFormats\nprint(length(im))## [1] 1\nimsub <- im[[1]]\nplot(imager::as.cimg(imsub), main = paste0('Image dimensions: ', paste(dim(imsub), collapse = ' x ') ))\nfile <- unique( params$global_coords[params$global_coords$fov==params$fov_names, 'image_file'] )[1]\nseries <- which( params$fov_names == params$current_fov )\nim <- readImage( \n  file, \n  nchannels = 4, # The image has 4 channels total\n  nzs = 1,\n  series = series )\nprint( length(im) ) #4 channels## [1] 4\nimsub <- im[[2]]\nplot(imager::as.cimg( imsub ), main = paste0('Image dimensions: ', paste(dim(imsub), collapse = ' x ') ) )## Warning in as.cimg.array(imsub): Assuming third dimension corresponds to time/depth\nim <- readImage( \n  file,\n  nchannels = 4,\n  nzs = 1,\n  series = series, \n  channelIndex = 2 )\nprint(length(im)) #Only 1 channel loaded## [1] 1\nimsub <- im[[1]]\nplot(imager::as.cimg(imsub), main = paste0('Image dimensions: ', paste(dim(imsub), collapse = ' x ') ) )## Warning in as.cimg.array(imsub): Assuming third dimension corresponds to time/depth\nimList <- readImageList( params$current_fov )\nnames(imList)##  [1] \"0_cy7\"      \"0_cy5\"      \"0_alexa594\" \"0_cy3\"      \"1_cy7\"      \"1_cy5\"      \"1_alexa594\" \"1_cy3\"      \"2_cy7\"      \"2_cy5\"      \"2_alexa594\"\n## [12] \"2_cy3\"      \"3_cy7\"      \"3_cy5\"      \"3_alexa594\" \"3_cy3\""},{"path":"spotcalling.html","id":"establishing-global-image-parameters","chapter":"3 Spotcalling","heading":"3.2.2 Establishing global image parameters","text":"first step, recommended determine dynamic range intensity values: .e. brightness value (.e. minimum brightness / floor) (.e. maximum brightness / ceiling) can safely ignore gradation. sensible minimum brightness intensities background pixels tissue imaged. maximum brightness, want cap super-threshold intensities can effectively considered ‘’. Ideally, limits relatively consistent across FOVs.created function getAnchorParams loads multiple FOVs attempts get global image parameters. default, brightness_max brightness_min returned. details, see documentation getAnchorParams.values appended params:Anchor FOVs used derive global image parameters. can user-specified, automatically determined getAnchorParams. automatic, nSamples number FOVs randomly selected. can visualised (red) running getAnchorParams:Random sampling work cases. regular FOVs, users may instead opt grid-based selection FOVs: evenly spaced FOVs internal outermost ring FOVs selected. [Since re-obtaining anchor metrics, set freshAnchors true.]returns different subset anchors.Users ensure sufficient anchors chosen representative brightness caps floors obtained. Additionally, different brightness caps / floors may required different samples, depending consistent imaging parameters across samples. Inconsistent imaging parameters may expected samples e.g. imaged different days.Additionally, users wish obtain global parameters, can achieved altering imageFunctions summaryFunctions fields getAnchorParams.instance, say wish also obtain mean brightness per image (brightness_mean). first write function perform (custom_getMeanBrightness), looped every anchor FOV. include function among named list users_imageFunctions, input imageFunctions. returns vector mean brightness values every anchor image, summarised corresponding function summaryFunctions (default, recommend conservativeMean – explained later – summary function robust outliers).conservativeMean: function takes mean within specific range, delimited certain number standard deviations (default = 0.9). return mean values less skewed outliers. alternative median, user-defined function.evaluate suitability chosen thresholds, users can refer troubleshootPlots environment returned returnTroubleShootPlots true.metric, also report observed thresholds quantile anchor image’s pixel intensity. can found ANCHOR_QUANTILEQC.csv file. expect brightness floors low quantile across FOVs (unless empty FOVs included), brightness ceilings high quantiles.","code":"\ngetAnchorParams( nSamples = 6 )\nparams$brightness_min##  [1] 0.02665484 0.07892208 0.02916114 0.04901184 0.03023053 0.06347031 0.02397402 0.04414353 0.02355671 0.07126881 0.02574727 0.04234602 0.02069601\n## [14] 0.06184499 0.02228692 0.04452783\nprint(params$anchors)## [1] \"MMStack_1-Pos_001_003\" \"MMStack_1-Pos_005_000\" \"MMStack_1-Pos_007_009\" \"MMStack_1-Pos_008_009\" \"MMStack_1-Pos_009_001\" \"MMStack_1-Pos_002_003\"\nprint(params$anchors_plot)\ngetAnchorParams( anchorMode = 'grid', returnTroubleShootPlots = T, freshAnchors = T )\nprint(params$anchors)##  [1] \"MMStack_1-Pos_001_001\" \"MMStack_1-Pos_001_003\" \"MMStack_1-Pos_001_005\" \"MMStack_1-Pos_001_007\" \"MMStack_1-Pos_003_002\" \"MMStack_1-Pos_003_004\"\n##  [7] \"MMStack_1-Pos_003_006\" \"MMStack_1-Pos_003_008\" \"MMStack_1-Pos_005_001\" \"MMStack_1-Pos_005_003\" \"MMStack_1-Pos_005_005\" \"MMStack_1-Pos_005_007\"\n## [13] \"MMStack_1-Pos_007_002\" \"MMStack_1-Pos_007_004\" \"MMStack_1-Pos_007_006\" \"MMStack_1-Pos_007_008\"\nprint(params$anchors_plot)\ncustom_getMeanBrightness <- function( im, ... ){\n  meanBrightness <- mean( im )\n  return( meanBrightness )\n}\nusers_imageFunctions = list(\n  'brightness_min' = imsBrightnessMin_MIP, #MIP for Z-stacks\n  'brightness_max' = imsBrightnessMax_MIP,\n  'brightness_mean' = custom_getMeanBrightness\n)\nusers_summaryFunctions = list(\n  'brightness_min' = conservativeMean,\n  'brightness_max' = conservativeMean,\n  'brightness_mean' = conservativeMean\n)\ngetAnchorParams( \n  imageFunctions = users_imageFunctions, \n  summaryFunctions = users_summaryFunctions,\n  anchorMode = 'grid'\n)\nset.seed(12345)\ntest <- rgamma( 1E4, 2, 1 )\nhist( test, breaks=100, main='Histogram of values with mean (red) and conservativeMean (blue)', xlab='Gamma distribution' ); \nabline(v=mean(test), col='red'); \nabline(v=conservativeMean(test, nSDs = 0.9), col='blue')\nmetric = 'brightness_min'\nbit_number = 1\nprint( troubleshootPlots[[ metric ]][[ bit_number ]] )\nhead(read.csv( paste0(params$out_dir, 'ANCHOR_QUANTILEQC.csv')))##           metric bit MMStack_1.Pos_001_001 MMStack_1.Pos_001_003 MMStack_1.Pos_001_005 MMStack_1.Pos_001_007 MMStack_1.Pos_003_002 MMStack_1.Pos_003_004\n## 1 brightness_min   1             0.9187895             0.1231919             0.2534933             0.2073274             0.2458487             0.5588561\n## 2 brightness_max   1             0.9999800             0.9998100             0.9997967             0.9998654             0.9998590             0.9999914\n## 3 brightness_min   2             0.9205798             0.1248851             0.2626584             0.2286615             0.2431207             0.5643622\n## 4 brightness_max   2             0.9995589             0.9855621             0.9769110             0.9885266             0.9930865             0.9991272\n## 5 brightness_min   3             0.9230520             0.1136280             0.2583598             0.1959322             0.2110254             0.4886617\n## 6 brightness_max   3             1.0000000             1.0000000             0.9999945             1.0000000             0.9999952             1.0000000\n##   MMStack_1.Pos_003_006 MMStack_1.Pos_003_008 MMStack_1.Pos_005_001 MMStack_1.Pos_005_003 MMStack_1.Pos_005_005 MMStack_1.Pos_005_007\n## 1             0.5077519            0.10864865            0.08566187             0.4722320             0.6327399             0.1366108\n## 2             0.9999982            0.99961480            0.99916499             0.9999821             1.0000000             0.9998951\n## 3             0.5056256            0.13454552            0.08949598             0.4169337             0.4555937             0.1668553\n## 4             0.9994388            0.99336617            0.87119601             0.9991592             0.9993902             0.9972692\n## 5             0.4099523            0.09494156            0.08018513             0.3478341             0.3117073             0.1181132\n## 6             1.0000000            0.99999726            0.99997740             1.0000000             1.0000000             0.9999995\n##   MMStack_1.Pos_007_002 MMStack_1.Pos_007_004 MMStack_1.Pos_007_006 MMStack_1.Pos_007_008\n## 1             0.1784223             0.4619367             0.1657847             0.9504158\n## 2             0.9999053             0.9999768             0.9998435             0.9999966\n## 3             0.1792000             0.5029208             0.1761314             0.9576270\n## 4             0.9932534             0.9988799             0.9904303             0.9999356\n## 5             0.1452180             0.4117146             0.1251103             0.9552260\n## 6             1.0000000             1.0000000             0.9999977             1.0000000"},{"path":"spotcalling.html","id":"maximum-intensity-projection","chapter":"3 Spotcalling","heading":"3.3 Maximum intensity projection","text":"Z stacks, default maximum intensity projection (MIP) collapse 3D array 2D matrix. [slices, 2D matrix returned unchanged.]Also note similarly performs MIP (possible) prior finding minimum / maximum brightnesses.Users wishing process Z slices individually encouraged refer Troubleshooting (Chapter 8) details.","code":"\ntoy_example <- array( c(\n  matrix(0:11 / 12, nrow = 3, ncol = 4, byrow = T),\n  matrix(11:0 / 12, nrow = 3, ncol = 4, byrow = T)\n), dim = c(3, 4, 2)\n)\nmip <- maxIntensityProject(toy_example)\npar(mfrow=c(1,3))\nplot( imager::as.cimg(toy_example[,,1]), main = 'Z slice 1', interpolate = F, rescale = F)\nplot( imager::as.cimg(toy_example[,,2]), main = 'Z slice 2', interpolate = F, rescale = F)\nplot( imager::as.cimg(mip), main = 'MIP', interpolate = F, rescale = F)\npar(mfrow=c(1,1))\nmasmr::imsBrightnessMin_MIP## function (im, zDim = 3, ...) \n## {\n##     if (length(dim(im)) != 2) {\n##         im <- suppressWarnings(maxIntensityProject(im, zDim = zDim))\n##     }\n##     result <- imsBrightnessMin(im, ...)\n##     return(result)\n## }\n## <bytecode: 0x0000024257609d40>\n## <environment: namespace:masmr>"},{"path":"spotcalling.html","id":"looping-through-images","chapter":"3 Spotcalling","heading":"3.4 Looping through images","text":"establishing global parameters (e.g. brightness floors ceilings), now ready loop image data. strongly recommended user keeps track current FOV processed params$current_fov follows:","code":"\nfor( fovName in params$fov_names ){\n  \n  ## Report current FOV / iteration \n  cat( paste0('\\n', fovName, ': ', \n  which(params$fov_names==fovName), ' of ', \n  length(params$fov_names), '...' ))\n  \n  ## Check if file has been created\n  if( params$resumeMode ){\n    checkFile <- file.exists( paste0(params$out_dir, 'SPOTCALL_', fovName, '.csv.gz') )\n    if(checkFile){\n      cat('FOV has been processed...Skipping...')\n      next\n    }\n  }\n  \n  ## Save the current_fov\n  params$current_fov <- fovName\n  \n  ## Load image\n  imList <- readImageList( params$current_fov )\n  \n  ## If needed, MIP for each channel\n  imList <- maxIntensityProject( imList )\n  \n  ## Image processing functions etc...\n}"},{"path":"spotcalling.html","id":"default-image-processing","chapter":"3 Spotcalling","heading":"3.4.1 Default image processing","text":"Designing custom image processing functions topic worthy chapter (Chapter 4). now, use default processing provided masmr:processed images stored new imMetrics environment, can visualised follows:","code":"\ngetImageMetrics( imList )## \npar(mfrow=c(2,3))\nfor( imMetricName in ls(imMetrics) ){\n  imsub <- imMetrics[[imMetricName]][[1]]\n  plot(imager::as.cimg(imsub[1000:1500, 1000:1500, 1] ), main = imMetricName)\n}\npar(mfrow=c(1,1))"},{"path":"spotcalling.html","id":"image-registration","chapter":"3 Spotcalling","heading":"3.4.2 Image registration","text":"Images FOV rarely perfect overlaps due imprecise microscope movements. Additionally, optical distortions (e.g. chromatic aberration), may also cause images different channels become unaligned. thus highly recommended align images downstream decoding (.e. image registration).user decide image processing perform obtain images ideal registration. recommend combination low-pass high-pass features: , combine images COARSE DECODE imMetrics (.e. band pass filtering).Registration accomplished registerImages function. function works maximising cross-correlation two images (Fourier transformed space). [Strictly, cross-correlation first passed Gaussian filter centred around origin, upweight small shifts. Gaussian filter parameters can tweaked using relevant parameters – see documentation registerImages. Additionally, image stack detected, maximum intensity projection performed registration.]function adds necessary coordinate offsets params environment object. Shift vectors (coordinates general) typically handled complex numbers masmr; real component reflecting x-coordinate imaginary, y.offsets added existing coordinates better align images. evaluate registration, users can set returnTroubleShootPlots registerImages true (returns troubleshootPlots object), use register_troubleshootPlots directly (see documentation).default plot registrations respect reference FOV (red). window centred brightest pixel reference FOV selected default.Additionally, registerImages function also saves reference bit image REGIM_{ FOV Name }.png file part default behaviour. can called subsequent stitching.","code":"\nforReg <- list()\nfor(i in 1:length(imList)){\n  forReg[[i]] <- imNormalise( imMetrics$COARSE[[i]] + imMetrics$DECODE[[i]] )\n}\nnames(forReg) <- names(imList) #Always keep the names from imList\nnorm <- forReg[[1]]\npar(mfrow=c(1,2))\nplot( imager::as.cimg(norm), main = 'Band pass' )## Warning in as.cimg.array(norm): Assuming third dimension corresponds to time/depth\nplot( imager::as.cimg(norm[1000:1500, 1000:1500, 1]), main = 'Band pass (Zoom in)' )\npar(mfrow=c(1,1))\nregisterImages(forReg, returnTroubleShootPlots = T)## Warning in maxIntensityProject(imsub): 2D matrix provided...Skipping MIP...\nprint( params$shifts )##      0_cy7      0_cy5 0_alexa594      0_cy3      1_cy7      1_cy5 1_alexa594      1_cy3      2_cy7      2_cy5 2_alexa594      2_cy3      3_cy7 \n##   0+0i   0+0i   0+0i   0-1i  -5+3i  -5+3i  -5+2i  -5+2i -12+5i -12+5i -11+4i -11+3i -14+2i\n##      3_cy5 3_alexa594      3_cy3 \n## -14+2i -14+3i -14+2i\np <- troubleshootPlots[['REGISTRATION_EVAL']][[1]][['PRE_REGISTER']]\nprint(\n  p + ggtitle('Before registration')\n)\np <- troubleshootPlots[['REGISTRATION_EVAL']][[1]][['POST_REGISTER']]\nprint(\n  p + ggtitle('After registration')\n)\nfile.exists( paste0(params$out_dir, 'REGIM_', params$current_fov, '.png') )## [1] TRUE"},{"path":"spotcalling.html","id":"working-with-pixel-wise-metrics","chapter":"3 Spotcalling","heading":"3.5 Working with pixel-wise metrics","text":"aligned processed images, next steps compile images manageable data format, perform decoding, successively filter low quality pixels.","code":""},{"path":"spotcalling.html","id":"moving-from-image-lists-to-a-dataframe","chapter":"3 Spotcalling","heading":"3.5.1 Moving from image lists to a dataframe","text":"first step convert images dataframe easier use. Hereafter, decoding filtering performed dataframe. accomplished consolidateImageMetrics. Additionally, previous image lists longer needed, recommended users clean environment cleanUp.troubleshooting, users may wish keep imMetrics environment time . However, note tends big object may stretch memory requirements. [One solution, shown , just keep subset objects imMetrics.]result dataframe unified coordinate system, pixels rows image metrics columns.","code":"\nspotcalldf <- consolidateImageMetrics()\n\nprint( paste0('Size of entire imMetrics: ', sum(sapply(ls(imMetrics), function(x) as.numeric(object.size(imMetrics[[x]])))) * 1E-9, ' Gb') )## [1] \"Size of entire imMetrics: 5.04670648 Gb\"\nfor( ix in ls(imMetrics) ){\n  if( ix %in% c('DECODE') ){ next }\n  remove( list=ix, envir=imMetrics )\n}\nprint( paste0('Size of imMetrics after filtering: ', sum(sapply(ls(imMetrics), function(x) as.numeric(object.size(imMetrics[[x]])))) * 1E-9, ' Gb') )## [1] \"Size of imMetrics after filtering: 1.121489776 Gb\"\ncleanUp( c(\n  'spotcalldf', #Necessary: must be specified, otherwise the dataframe will be deleted\n  'imMetrics', #Optional: keep if want to make use of images in filterDF() later\n  cleanSlate) #Other things to keep\n)\nknitr::kable( head( spotcalldf ), format = 'html', booktabs = TRUE )"},{"path":"spotcalling.html","id":"decoding","chapter":"3 Spotcalling","heading":"3.5.2 Decoding","text":"Decoding involves calculating distances image metric vectors expected vectors codebook. default, decode function takes columns DECODE_XX format calculatesCOS: cosine distances,EUC: Euclidean distances,L2E: L2-normalised Euclidean distancesbetween image codebook vectors. nearest match next nearest match (prefixed B) returned.relationship different distance metrics illustrated .stage, pixels assigned preliminary gene label g column. default, dependent nearest codebook match cosine distance (column COSLAB dataframe).","code":"\nspotcalldf <- decode(spotcalldf)\ncowplot::plot_grid( plotlist = list(\n  ggplot( spotcalldf ) +\n    geom_hex(aes(x=COS, y=L2E), bins=100) +\n    scale_fill_viridis_c(option = 'turbo', trans='log10') +\n    theme_minimal(base_size=14) +\n    theme(legend.position = 'top'),\n  ggplot( spotcalldf ) +\n    geom_hex(aes(x=COS, y=EUC), bins=100) +\n    scale_fill_viridis_c(option = 'turbo', trans='log10') +\n    theme_minimal(base_size=14) +\n    theme(legend.position = 'top'),\n  ggplot( spotcalldf ) +\n    geom_hex(aes(x=EUC, y=L2E), bins=100) +\n    scale_fill_viridis_c(option = 'turbo', trans='log10') +\n    theme_minimal(base_size=14) +\n    theme(legend.position = 'top')\n), nrow=1 )\nknitr::kable( head(spotcalldf[,grepl('^g$|LAB$', colnames(spotcalldf))]), format = 'html', booktabs = TRUE )"},{"path":"spotcalling.html","id":"annotating-blanks","chapter":"3 Spotcalling","heading":"3.5.3 Annotating blanks","text":"Users recommended filter pixels large distance metrics: .e. confidently decode. thresholds can determined priori, determined empirically finding threshold separates blanks non-blank calls.several ways define “blanks” provided masmr:gBlank: Whether name gene assigned given pixel word “blank” .bPossible: Whether next closest gene label selected distance metrics possible.gbPossible: Whether next closest gene label default distance metric (COS) possible.consistentLabel: Whether gene labels agree across distance metrics.default, gBlank, gbPossible, consistentLabel tests run. number tests failed reported scoreBlanks.Say decide “blanks” fail even one test. can examine range distance metrics blanks non-blanks. general, distance metrics larger blanks.reasonable distance threshold might average medians. can easily obtained findThreshold thresh_Quantile function (see documentation details).","code":"\nnBlankTestsFailed <- scoreBlanks( spotcalldf )\ntable(nBlankTestsFailed)## nBlankTestsFailed\n##       0       1       2       3 \n## 2039428  616429  255396       2\nspotcalldf$BLANK <- nBlankTestsFailed >0\nggplot( reshape2::melt(spotcalldf, measure.vars=c('COS', 'EUC', 'L2E'))  ) +\n  geom_violin(aes(x=BLANK, y=value, colour=BLANK) ) +\n  geom_boxplot(aes(x=BLANK, y=value, colour=BLANK), fill='transparent', width=0.25 ) +\n  facet_wrap(~variable, scales='free') +\n  ylab('') +\n  theme_minimal(base_size=14) +\n  scale_colour_manual(values=c('TRUE' = 'red', 'FALSE' = 'black')) +\n  theme(legend.position = 'none')\nfiltout <- rep(0, nrow(spotcalldf))\nfor( distanceMetric in c('COS', 'EUC', 'L2E') ){\n  thresh <- thresh_Quantile( spotcalldf[,distanceMetric], label = spotcalldf$BLANK, quantileFalse = 0.5, quantileTrue = 0.5 )\n  cat(paste0( '\\n', distanceMetric, ' threshold: ', thresh ))\n  filtout <- filtout + spotcalldf[,distanceMetric] > thresh\n}## \n## COS threshold: 0.222254471692498\n## EUC threshold: 3.30408867238758\n## L2E threshold: 0.326703039218853\ntable(filtout > 0)## \n##   FALSE    TRUE \n##  824288 2086967"},{"path":"spotcalling.html","id":"filtering-and-evaluating-your-choice-of-filter","chapter":"3 Spotcalling","heading":"3.5.4 Filtering and evaluating your choice of filter","text":"decide good filter apply data?One idea use priori knowledge gene distributions space. instance, example dataset organoid, expect dividing cells concentrated near lumen. Accordingly, filtering enrich lumenal MKI67 (marker cell division).Another option consider filtering changes quality control metrics: e.g. good filter generally increase correlation count profiles previously obtained FPKM data, decrease percentage blanks relative true genes, etc. provide filterDF function reports given filter changes QC metrics (relevant files specified establishParams).Perhaps safest option – one require priori assumptions – perform decoding eye small FOV region, ensure one’s spotcalling pipeline returns results agree manually obtained results. attempt , provide returnTroubleShootPlots parameter filterDF. set TRUE (default FALSE), plots returned showing pixel intensity images bit, overlaid gene labels. [note plots available users kept imMetrics environment, specified list images (imList).]Plots show spots either filtering.hood, filterDF makes use spotcall_troubleshootPlots function return plots, parameters spotcall_troubleshootPlots can input filterDF modify plots returned. Alternatively, users may simply use spotcall_troubleshootPlots directly (see documentation).Users encouraged optimise image processing pipelines one FOV, applying pipelines FOVs.","code":"\ncowplot::plot_grid( plotlist = list(\n  ggplot( spotcalldf[filtout>0 & spotcalldf$g=='MKI67',] ) +\n    geom_hex(aes(x=WX, y=WY), bins=100) +\n    scale_fill_viridis_c(option='turbo', trans='log10') +\n    scale_y_reverse() +\n    theme_void( base_size = 14 ) +\n    coord_fixed() + ggtitle('Drop'),\n  \n  ggplot( spotcalldf[filtout==0  & spotcalldf$g=='MKI67',] ) +\n    geom_hex(aes(x=WX, y=WY), bins=100) +\n    scale_fill_viridis_c(option='turbo', trans='log10') +\n    scale_y_reverse() +\n    theme_void( base_size = 14 ) +\n    coord_fixed() + ggtitle('Keep')\n), nrow=1)\nparams$verbose <- TRUE ## To see output of filterDF, verbose is changed to True\nspotcalldf <- filterDF(spotcalldf, filtout>0, returnTroubleShootPlots = T, plotWindowRadius = 5)## \n## Applying filter: filtout > 0...## N pixels: 2911255 ( 100% ) --> 824288 ( 28.31% )## N blanks: 871827 ( 29.95% ) --> 207062 ( 25.12% )## LogFPKM Corr: 0.58239 --> 0.59519## LogN Probes Corr: 0.52337 --> 0.51121\nparams$verbose <- FALSE ## Turn it back off if want to avoid messages entirely (warnings and errors will still be given)\nprint( troubleshootPlots[['BEFORE']][[1]] )\nprint( troubleshootPlots[['AFTER']][[1]] )\n## An example\nplotList <- spotcall_troubleshootPlots( \n  spotcalldf, \n  plotWindowRadius = 5, \n  decodeMetric = 'DECODE', #Instead of DECODE, users may pick other objects in imMetrics\n  chosenCoordinate = c(\n    939 + 340i, #Specifying a custom coordinate\n    sum(as.numeric(spotcalldf[1,c('WX', 'WY')]) * c(1, 1i)) #Specifying the first pixel in spotcalldf\n    )\n  )\nfor( i in 1:length(plotList) ){\n  p <- plotList[[i]]\n  print( p )\n}"},{"path":"spotcalling.html","id":"binarising-continuous-values","chapter":"3 Spotcalling","heading":"3.5.5 Binarising continuous values","text":"Note current image vector contains continuous values. Users may wish binarise values, superthreshold values unambiguously assigned , subthreshold . end, provide bitsFromDecode function searches optimal threshold maximises accuracy /calls per bit. several ways assay accuracy:precision: True positives / (True positives + False positives)recall: True positives / (True positives + False negatives)f1 (default): 2 * Precision * Recall / (Precision + Recall)fb: (1 + \\(\\beta^2\\)) * Precision * Recall / (\\(\\beta^2\\) * Precision + Recall)thresholding, can also calculate Hamming Distance codebook vectors, stored HD column.recommended filter pixels whose Hamming Distance assigned gene >1.Binarisation recommended clear cutoff intensities 0 vs 1 bits DECODE images. assumption true cases, may violated different numbers encoding probes different genes: e.g. gene 40 probes gene B 5 probes, gene B dimmer gene (gene may brighter gene B, depending thorough bleaching / washing imaging cycles). single intensity threshold separating vs may appropriate . scenario, users may wish skip binarisation entirely.","code":"\nspotcalldf <- bitsFromDecode(spotcalldf)\ntable(spotcalldf$HD)## \n##      0      1      2      3      4      5      6      7      8      9 \n##  46125 288300 296934 124675  46694  15838   4772    851     94      5\nspotcalldf <- filterDF(spotcalldf, spotcalldf$HD > 1)"},{"path":"spotcalling.html","id":"obtaining-other-qc-metrics","chapter":"3 Spotcalling","heading":"3.5.6 Obtaining other QC metrics","text":"Beyond image-codebook vector distances, also provide functions users may find useful performing quality control checks. provide several options thresholding:thresh_Otsu: Otsu thresholding. Useful separating bimodal distribution.thresh_Elbow: Identifies elbow distribution. Useful heavy tailed distributions.thresh_Quantile: Finds average quantiles group vs B. default, chosen quantiles medians B.thresholding functions compatible findThreshold function.","code":"\nset.seed(12345)\ngroups <- sample(c(F, T), 1E4, T, c(0.5, 0.5))\nvalues <- rep(0, length(groups))\nvalues[groups] <- rnorm(sum(groups), mean = 1, sd = 0.1)\nvalues[!groups] <- rgamma(sum(!groups), shape = 1, scale = 0.5)\nhist(values, breaks=1000, main = 'Thresholds: Otsu (red), Elbow (blue), Quantile (green)' ); \nabline(v=findThreshold(values, thresh_Otsu), col='red');\nabline(v=findThreshold(values[values > median(values)], thresh_Elbow, rightElbow = T), col='blue');\nabline(v=findThreshold(values, thresh_Quantile, labels = groups), col='green')"},{"path":"spotcalling.html","id":"scoredeltaf","chapter":"3 Spotcalling","heading":"scoreDeltaF","text":"function calculates \\(\\Delta F / F_0\\) metrics across image metrics. default, image metrics generated getImageMetrics (whose names saved params$imageMetrics) processed. [NB \\(F_0\\) 0, \\(\\Delta F / F_0\\) default set highest valid value column.], show \\(\\Delta F / F_0\\) alone, users read scoreDeltaF documentation full list metrics returned (e.g. \\(F_1\\), \\(F_0\\) etc).expect low confidence spots average low \\(\\Delta F / F_0\\), .e. bits less distinguishable bits.","code":"\nspotcalldf <- scoreDeltaF( spotcalldf )\nknitr::kable( head( spotcalldf[,grepl('^DFF0_', colnames(spotcalldf))] ), format = 'html', booktabs = TRUE )\nggplot(spotcalldf[spotcalldf$F0_DECODE!=0,]) +\n  geom_violin(aes(x=BLANK, y=DFF0_DECODE, colour=BLANK) ) +\n  geom_boxplot(aes(x=BLANK, y=DFF0_DECODE, colour=BLANK), fill='transparent', width=0.25 ) +\n  scale_y_log10() +\n  theme_minimal(base_size=20) +\n  scale_colour_manual(values=c('TRUE' = 'red', 'FALSE' = 'black')) +\n  theme(legend.position = 'none')"},{"path":"spotcalling.html","id":"spatialisadjacent","chapter":"3 Spotcalling","heading":"spatialIsAdjacent","text":"spatialIsAdjacent function searches immediate surroundings set query coordinates. instance, , ask given pixel next blank. [Unsurprisingly, blanks reported next blanks.]general, less confident non-blank spots next blanks, evidenced higher codebook distances .Users may thus wish “trim” pixel clusters, removing non-blanks next blanks: beneficial clustering (described later). [Obviously, blanks subject filtering.]","code":"\nisNextToBlank <- spatialIsAdjacent( spotcalldf, 'BLANK' )\nby(isNextToBlank, spotcalldf$BLANK, table)## spotcalldf$BLANK: FALSE\n## \n##  FALSE   TRUE \n## 240735  16688 \n## ------------------------------------------------------------------------------------------------------------------ \n## spotcalldf$BLANK: TRUE\n## \n##  TRUE \n## 77002\nspotcalldf$NEXTTOBLANK <- isNextToBlank\nggplot( reshape2::melt( data.frame(spotcalldf)[!spotcalldf$BLANK, ], measure.vars=c('COS', 'EUC', 'L2E'))  ) +\n  geom_violin(aes(x=NEXTTOBLANK, y=value, colour=NEXTTOBLANK) ) +\n  geom_boxplot(aes(x=NEXTTOBLANK, y=value, colour=NEXTTOBLANK), fill='transparent', width=0.25 ) +\n  facet_wrap(~variable, scales='free') +\n  ylab('') +\n  theme_minimal(base_size=14) +\n  scale_colour_manual(values=c('TRUE' = 'red', 'FALSE' = 'black')) +\n  theme(legend.position = 'none') +\n  ggtitle('Non-blank spots') + xlab('Is next to a blank')\nspotcalldf <- filterDF(spotcalldf, spotcalldf$NEXTTOBLANK & !spotcalldf$BLANK)"},{"path":"spotcalling.html","id":"spatialhnndist","chapter":"3 Spotcalling","heading":"spatialHNNDist","text":"Another useful spatial metric far apart two pixels identity , called “homotypic nearest neighbour (HNN) distance”. can calculated using spatialHNNDist.general, blanks less likely next (possibly erroneous single pixel calls noisy regions), spots gene tend cluster - .e. tend low HNN distances (). Users typically perform thresholding HNN distances given later clustering step; though distribution distances can helpful determining minimum intracluster distances later .","code":"\nHNNDist <- spatialHNNDist( spotcalldf )\nspotcalldf$HNNDIST <- HNNDist\nhnnDistBins <- factor(cut(spotcalldf$HNNDIST, breaks=c(0,1,2,3,4,5,Inf)))\nggplot( data.frame(spotcalldf, hnnDistBins)  ) +\n  scale_fill_viridis_d(name = 'HNN distance range (pixels)', option='turbo') +\n  geom_bar(aes(x=BLANK, fill=hnnDistBins), position='fill' ) +\n  theme_minimal(base_size=14) +\n  theme(legend.position = 'right') + ylab('Proportion')"},{"path":"spotcalling.html","id":"scoreclassifier","chapter":"3 Spotcalling","heading":"scoreClassifier","text":"Finally, scoreClassifier function. hood, function builds classifier (logistic regression default) distinguish one class pixels another, using pixel-wise metrics dataframe. Users can specify covariates include model; otherwise, columns dataframe used.example predicting blanks non-blanks. exclude bit-specific columns (e.g. DECODE_01), covariates likely highly correlate others (e.g. F1_DECODE DFF0_DECODE likely highly correlate), coordinate information, covariate equivalent BLANK.Accordingly probability blank higher blanks non-blanks.Thresholding filtering can performed using classifier scores:","code":"\nforExclusion <- c('Xm', 'Ym', 'fov', 'g', 'WX', 'WY', 'IDX', colnames(spotcalldf)[grepl('_\\\\d+$|^DFF0_|^F1_|CV_|LAB$', colnames(spotcalldf))])\nprobabilityBLANK <- scoreClassifier(spotcalldf, 'BLANK', variablesExcluded = forExclusion)\nspotcalldf$PBLANK <- probabilityBLANK\nthresh <- thresh_Quantile(spotcalldf$PBLANK, spotcalldf$BLANK, quantileFalse = 0.5, quantileTrue = 0.25)\nggplot( spotcalldf  ) +\n  geom_violin(aes(x=BLANK, y=PBLANK, colour=BLANK) ) +\n  geom_boxplot(aes(x=BLANK, y=PBLANK, colour=BLANK), fill='transparent', width=0.25 ) +\n  ylab('Probability of being a blank') +\n  theme_minimal(base_size=14) +\n  scale_colour_manual(values=c('TRUE' = 'red', 'FALSE' = 'black')) +\n  theme(legend.position = 'none') +\n  geom_hline(yintercept=thresh, linetype = 'dashed', colour='grey')\nspotcalldf <- filterDF(spotcalldf, spotcalldf$PBLANK > thresh)"},{"path":"spotcalling.html","id":"clustering","chapter":"3 Spotcalling","heading":"3.5.7 Clustering","text":"performed QC focus pixels whose identity confident , next step cluster adjacent pixels identity single punctum. accomplished spatialClusterLeiden function. , want clusters least 3 pixels big, maximum distance pixels 2 pixels.Users recommended visualise clusters across small window. Note specifying centroids returns single pixel coordinate per cluster.Depending user wants, non-centroid pixels can filtered. Additionally, users may wish examine cluster sizes find appropriate range pixels per cluster., filtering accomplished filterDF:","code":"\nclusterInfo <- spatialClusterLeiden( spotcalldf, minNeighbours = 3, maxInterSpotDistancePixels = 2)\nspotcalldf[,colnames(clusterInfo)] <- clusterInfo\n## Specify window to plot\ncxWindow <- c(1200, 1300, 1200, 1300)\n\n## Specify what genes assigned which colours\n## Manually:\n# genePalette <- setNames(\n#   viridis::turbo(nrow(params$ordered_codebook)),\n#   rownames(params$ordered_codebook) )\n## Using previously established palette (established during prepareCodebook):\ngenePalette <- params$genePalette\n\n## Plot of labelled pixels vs centroids   \ncowplot::plot_grid( plotlist = list(\n  ggplot( \n    spotcalldf[\n      spotcalldf$WX > cxWindow[1] \n      & spotcalldf$WX < cxWindow[2] \n      & spotcalldf$WY > cxWindow[3] \n      & spotcalldf$WY < cxWindow[4], ]\n    ) + \n    geom_text( aes(\n      x=WX, y=WY, label=g, \n      colour=factor(g, levels=rownames(params$ordered_codebook))) \n      ) +\n    scale_colour_manual( values=genePalette ) +\n    theme_void(base_size=14) +\n    theme(legend.position = 'none', \n          plot.title = element_text(hjust=0.5)) +\n    scale_x_continuous( limits=c(cxWindow[1], cxWindow[2]) ) +\n    scale_y_reverse( limits=c(cxWindow[4], cxWindow[3]) ) +\n    ggtitle('All pixels'),\n  \n    ggplot( \n    spotcalldf[\n      spotcalldf$CENTROID\n      & spotcalldf$WX > cxWindow[1] \n      & spotcalldf$WX < cxWindow[2] \n      & spotcalldf$WY > cxWindow[3] \n      & spotcalldf$WY < cxWindow[4], ]\n    ) + \n    geom_text( aes(\n      x=WX, y=WY, label=g, \n      colour=factor(g, levels=rownames(params$ordered_codebook))) \n      ) +\n    scale_colour_manual( values=genePalette ) +\n    theme_void(base_size=14) +\n    theme(legend.position = 'none', \n          plot.title = element_text(hjust=0.5)) +\n    scale_x_continuous( limits=c(cxWindow[1], cxWindow[2]) ) +\n    scale_y_reverse( limits=c(cxWindow[4], cxWindow[3]) ) +\n    ggtitle('Centroids only')\n  \n), nrow=1 )\nmaxClusterSize = 50\nggplot( spotcalldf[spotcalldf$CENTROID,] ) +\n  geom_histogram( aes(x=CLUSTER_SIZE, fill=BLANK), binwidth = 1) +\n  facet_wrap(~BLANK, ncol=1, scales='free_y', strip.position = 'right') +\n  theme_minimal(base_size=14) +\n  xlab('Cluster size') + ylab('N centroids') +\n  geom_vline(xintercept = maxClusterSize, col='grey', linetype='dashed') +\n  scale_fill_manual( values=c('FALSE' = 'black', 'TRUE' = 'red') )\nspotcalldf <- filterDF(spotcalldf, !(spotcalldf$CENTROID & spotcalldf$CLUSTER_SIZE < maxClusterSize) )"},{"path":"spotcalling.html","id":"saving-spot-calls","chapter":"3 Spotcalling","heading":"3.6 Saving spot calls","text":"satisified quality control, final step use saveDF function save dataframe. default output SPOTCALL_{ FOV Name }.csv.gz file; users set params$resumeMode TRUE may wish first check file exists proceeding image processing.Individual files thereby generated every FOV.","code":"\nsaveDF( spotcalldf )\nfile.exists( paste0(params$out_dir, 'SPOTCALL_', params$current_fov, '.csv.gz') )## [1] TRUE"},{"path":"image-processing.html","id":"image-processing","chapter":"4 Image processing","heading":"4 Image processing","text":"One key decision spotcalling script choosing process images. , cover image processing functions {masmr} provides, users may string together functions purposes.","code":"\nlibrary(masmr)\nlibrary(ggplot2)"},{"path":"image-processing.html","id":"pre-processing-1","chapter":"4 Image processing","heading":"4.1 Pre-processing","text":", specify parameters. [Parameters hashed automatically inferred default.]Image processing handled within spotcalling script, consequently requires pre-processing done prior looping images. provided (kindly refer Chapter 3 details).","code":"\ndata_dir = 'C:/Users/kwaje/Downloads/JIN_SIM/20190718_WK_T2_a_B2_R8_12_d50/'\nestablishParams(\n  \n  ## User to fill in\n  imageDirs = paste0(data_dir, 'S10/'),\n  imageFormat = '.ome.tif',\n  outDir = 'C:/Users/kwaje/Downloads/JYOUT/',\n  codebookFileName = list.files(paste0(data_dir,'codebook/'),pattern='codebook',full.names = TRUE),\n  dapiDir = paste0(data_dir, 'DAPI_1/'),\n  \n  ## Will attempt automatic fill\n  # metaFormat = '.ome.tif',\n  # dapiFormat = '.ome.tif',\n  codebookColumnNames = paste0(rep(c(0:3),4),'_',rep(c('cy3','alexa594','cy5','cy7'),each=4)),\n  pythonLocation = 'C:/Users/kwaje/AppData/Local/miniforge3/envs/scipyenv/',\n  \n  ## Automatically filled\n  # seed = 12345,\n  verbose = FALSE,\n  # resumeMode = TRUE,\n  \n  ## Optional (but recommended for QC checks)\n  fpkmFileName = paste0(data_dir, \"FPKM_data/Jin_FPKMData_B.tsv\"),\n  nProbesFileName = paste0(data_dir, \"ProbesPerGene.csv\")\n)## Assuming .ome.tif is extension for meta files...\n## Necessary pre-processing done before your loop\nreadImageMetaData()## Warning in readImageMetaData(): Updating params$fov_names\nprepareCodebook()\ngetAnchorParams()\nestablishCleanSlate()## [1] \".Random.seed\" \"data_dir\"     \"params\"\n## Specify the current FOV (done inside the loop)\nparams$current_fov <- params$fov_names[38]\n\n## Read the images for your current FOV (done inside loop)\nimList <- readImageList( params$current_fov )"},{"path":"image-processing.html","id":"building-blocks-of-image-processing","chapter":"4 Image processing","heading":"4.2 Building blocks of image processing","text":"backbone MERFISH pipelines image processing. provide several options, showcase test image . Note use imager::.cimg, converts image matrices .cimg objects read C++; allows rapid manipulation plotting.ALWAYS plot check image processing altered image!","code":"\nim <- imList[[1]]\npar(mfrow=c(1,2))\nplot( imager::as.cimg(im), main = 'Unaltered image' )\nhist( im, breaks=1000, main = 'Unaltered image', xlab='Intensities', ylab='N pixels' )\npar(mfrow=c(1,1))"},{"path":"image-processing.html","id":"imnormalise","chapter":"4 Image processing","heading":"imNormalise","text":"Note range raw intensities. can use imNormalise perform quick min-max normalisation values span 0 1.Since previously calculated min max brightnesses, may wish winsorise intensity values (.e. values trimmed lie min max brightness). , can use imNormalise time specifying desired floor ceiling values. [unspecified, floor ceiling values defaulted minimum maximum intensities observed image, thereby performing min-max normalisation.]","code":"\nnorm <- imNormalise(im)\npar(mfrow=c(1,2))\nplot( imager::as.cimg(norm), main = 'Min-max image' )\nhist( norm, breaks=1000, main = 'Min-max image', xlab='Intensities', ylab='N pixels' )\npar(mfrow=c(1,1))\nnorm <- imNormalise(im, floorVal = params$brightness_min[1], ceilVal = params$brightness_max[1] )\npar(mfrow=c(1,2))\nplot( imager::as.cimg(norm), main = 'Winsorised image' )\nhist( norm, breaks=1000, main = 'Winsorised image', xlab='Intensities', ylab='N pixels' )\npar(mfrow=c(1,1))"},{"path":"image-processing.html","id":"imautobrighten","chapter":"4 Image processing","heading":"imAutobrighten","text":"Brightening image accomplished raising intensities (lie 0 1) power \\(x\\), maximises distance two user-specified values (\\(floor\\) \\(ceiling\\)). optimal \\(x\\) found solving:\\[\\begin{align}\n\\frac{d}{dx}\\left(ceiling^x - floor^x\\right) = 0 \\\\\nceiling^x \\log{ceiling} - floor^x \\log{floor} = 0 \\\\\nx = \\frac{\\log{ \\frac{\\log{ceiling}}{\\log{floor}}} }{ \\log{\\frac{floor}{ceiling}} }\n\\end{align}\\]Note imAutoBrighten valid floor 0 ceiling less 1.basis imAutoBrighten function.","code":"\nnorm <- imAutoBrighten(im, floorVal = params$brightness_min[1], ceilVal = params$brightness_max[1] )\npar(mfrow=c(1,2))\nplot( imager::as.cimg(norm), main = 'Autobrightened image' )\nhist( norm, breaks=1000, main = 'Autobrightened image', xlab='Intensities', ylab='N pixels' )\npar(mfrow=c(1,1))"},{"path":"image-processing.html","id":"imlaplacianofgaussian","chapter":"4 Image processing","heading":"imLaplacianOfGaussian","text":"difference Gaussian blurs (.e. Laplacian Gaussians, LoG) useful correcting uneven lighting blob detection. accomplished subtracting image slightly blurred (determined smallBlur parameter) image blurrier (bigBlur).Values less 0 dimmer immediate surroundings. Spots typically brighter surroundings, typically LoG > 0.","code":"\nnorm <- imLaplacianOfGaussian(im, smallBlur = 1, bigBlur = 5 )\npar(mfrow=c(1,2))\nplot( imager::as.cimg(im[1000:1500, 1000:1500, 1]), main = 'Original image\\n(Zoom in)' )\nplot( imager::as.cimg(norm[1000:1500, 1000:1500, 1]), main = 'Laplacian of Gaussians\\n(Zoom in)' )\npar(mfrow=c(1,1))\nnorm <- imLaplacianOfGaussian(im, smallBlur = 1, bigBlur = 5 )\nnorm <- imNormalise(norm, 0, max(norm))\npar(mfrow=c(1,2))\nplot( imager::as.cimg(im[1000:1500, 1000:1500, 1]), main = 'Original image\\n(Zoom in)' )\nplot( imager::as.cimg(norm[1000:1500, 1000:1500, 1]), main = 'Laplacian of Gaussians >0\\n(Zoom in)' )\npar(mfrow=c(1,1))"},{"path":"image-processing.html","id":"imhessiandeterminant","chapter":"4 Image processing","heading":"imHessianDeterminant","text":"Hessian symmetric matrix containing second-order partial derivatives (.e. gradient gradients). context images, matrix intensity values changing move along rows columns image matrix. determinant Hessian (detHess) frequently used blob detection – thus created function calculates value:Thresholding detHess values quick way detecting puncta:Attentive readers noticed smallBlur parameter (default = 1) imHessianDeterminant function. blur serves denoise image, detHess values meaningful.","code":"\nnorm <- imHessianDeterminant(im, smallBlur = 1)\npar(mfrow=c(1,2))\nplot( imager::as.cimg(im[1000:1500, 1000:1500, 1]), main = 'Original image\\n(Zoom in)' )\nplot( imager::as.cimg(norm[1000:1500, 1000:1500, 1]), main = 'detHess\\n(Zoom in)' )\npar(mfrow=c(1,1))\nnorm <- imHessianDeterminant(im, smallBlur = 1)\nnorm <- norm>quantile(norm, 0.99) ##99 percentile of values\npar(mfrow=c(1,2))\nplot( imager::as.cimg(norm), main = 'detHess thresholded' )\nplot( imager::as.cimg(norm[1000:1500, 1000:1500, 1]), main = 'detHess thresholded (Zoom in)' )\npar(mfrow=c(1,1))\npar(mfrow=c(1,3))\nplot( imager::as.cimg(im[1200:1300, 1200:1300, 1]), main = 'Original image\\n(Zoom in, no blur)' )\nplot( imager::as.cimg(imHessianDeterminant(im[1200:1300, 1200:1300, 1], smallBlur = 0)), main = 'detHess\\n(Zoom in, no blur)' )\nplot( imager::as.cimg(imHessianDeterminant(im[1200:1300, 1200:1300, 1], smallBlur = 1)), main = 'detHess\\n(Zoom in, slight blur)' )\npar(mfrow=c(1,1))"},{"path":"image-processing.html","id":"imtvdenoise","chapter":"4 Image processing","heading":"imTVDenoise","text":"Total Variation (TV) denoising approach first described 1992 (Rudin, Osher, Fatemi 1992) remove noise image preserving edges. implemented Chambolle algorithm (Chambolle 2004) (explained detail elsewhere (Chambolle et al. 2010; Duran, Coll, Sbert 2013)) shown fast, stable (.e. relatively unchanged mean square error different hyperparameters), frequently outperforms denoising approaches astronomy data (Roscani et al. 2020).Currently, used imTVDenoise part default getImageMetrics pipeline (described later). Interested users can consider using alternative band-pass filtering Gaussian smoothing (imager::isoblur) creating image processing functions. main tuning parameter imTVDenoise denoisingWeight – higher values reducing fidelity original image.Note denoising reduces standard deviation pixel intensities.","code":"\ntoy_image <- im[1200:1300, 1200:1300, 1]\n\ndW1 = 0.001\ndenoised1 <- imTVDenoise(toy_image, denoisingWeight = dW1)\n\ndW2 = 0.01\ndenoised2 <- imTVDenoise(toy_image, denoisingWeight = dW2)\n\ndW3 = 0.1\ndenoised3 <- imTVDenoise(toy_image, denoisingWeight = dW3)\n\npar(mfrow=c(1,4))\nplot( \n  imager::as.cimg( toy_image ), interpolate = F, \n  main = paste0('Original image\\nIntensity SD: ', round(sd(as.vector(toy_image)), digits=6) )\n)\nplot( \n  imager::as.cimg( denoised1 ), interpolate = F, \n  main = paste0('Denoised image (weight=', dW1, ')\\nIntensity SD: ', round(sd(as.vector(denoised1)), digits=6) )\n)\nplot( \n  imager::as.cimg( denoised2 ), interpolate = F, \n  main = paste0('Denoised image (weight=', dW2, ')\\nIntensity SD: ', round(sd(as.vector(denoised2)), digits=6) )\n)\nplot( \n  imager::as.cimg( denoised3 ), interpolate = F, \n  main = paste0('Denoised image (weight=', dW3, ')\\nIntensity SD: ', round(sd(as.vector(denoised3)), digits=6) )\n)\npar(mfrow=c(1,1))"},{"path":"image-processing.html","id":"advanced-creating-your-own-building-blocks","chapter":"4 Image processing","heading":"4.3 Advanced: creating your own building blocks","text":"section, showcase several image processing vignettes users good grasp basics wishing explore topic depth. ideas covered may beyond scope intended purpose {masmr}, breadth knowledge often good fuel creativity.users interested functionality {masmr}, may skip ahead (Section 4.4).","code":""},{"path":"image-processing.html","id":"the-benefits-of-using-complex-numbers-to-represent-coordinates","chapter":"4 Image processing","heading":"The benefits of using complex numbers to represent coordinates","text":"Throughout {masmr} frequently represent 2D coordinates complex numbers, allowing us make use several -built functions base R quickly get distances angles.Additionally, can exploit different ways represent complex numbers easily move Cartesian Polar coordinate systems…\\[\\begin{align}\nx + yi = r(\\cos(theta) + \\sin(\\theta)) = re^{\\theta}\n\\end{align}\\]…make getting metrics distances angles much easier.Sampling using Polar coordinate variables can also incredibly helpful.Taking mean median complex number coordinates also quickly returns various “centres” point cloud. means plusses (+) medians crosses (x). obtained functions complex numbers red, obtained functions (x,y) individually blue.Note mean median (x,y) tend return centroids (centre mass), mean median x+yi (median returns point within cloud, mean returns centre mass).centre mass – respect origin – can used infer asymmetry / anisotropy point cloud distribution. Note distance origin now increased asymmetrical object.Summarising, encoding coordinates complex numbers allow us quickly simply obtain useful metrics.","code":"\ncoordinates = c(1+1i, -1+1i, -1-1i, 1-1i)\nfor( coordinate in coordinates ){\n  print( paste0(\n    coordinate, \n    ' (real: ', Re(coordinate), \n    ', imaginary: ', Im(coordinate),\n    ') has length sqrt(', Mod(coordinate)^2, ')', #The length is automatically returned with Mod\n    ', and angle ', Arg(coordinate) / pi * 180, ' degrees' #The default of Arg is in radians\n  ) )\n}## [1] \"1+1i (real: 1, imaginary: 1) has length sqrt(2), and angle 45 degrees\"\n## [1] \"-1+1i (real: -1, imaginary: 1) has length sqrt(2), and angle 135 degrees\"\n## [1] \"-1-1i (real: -1, imaginary: -1) has length sqrt(2), and angle -135 degrees\"\n## [1] \"1-1i (real: 1, imaginary: -1) has length sqrt(2), and angle -45 degrees\"\nx = 1\ny = 1\nr = sqrt( 2 )\ntheta = 45 / 180 * pi\n\nprint( complex(real = x, imaginary = y) )## [1] 1+1i\nprint( x + 1i*y )## [1] 1+1i\nprint( complex(modulus = r, argument = theta) )## [1] 1+1i\nprint( r * exp( 1i * theta ) )## [1] 1+1i\nprint( r * ( cos( theta ) + 1i * sin(theta) ) )## [1] 1+1i\ntoy_image <- matrix(0, nrow=51, ncol=51)\ntoy_coord <- getRasterCoords(toy_image)\ncentre = 25+25i\n\npar(mfrow=c(1,4))\nplot( imager::as.cimg( Re(toy_coord) ), interpolate = F, main = 'X coordinate' )\nplot( imager::as.cimg( Im(toy_coord) ), interpolate = F, main = 'Y coordinate' )\nplot( imager::as.cimg( Mod(toy_coord - centre) ), interpolate = F, main = 'Distance from centre' )\nplot( imager::as.cimg( Arg(toy_coord - centre) ), interpolate = F, main = 'Angle wrt centre' )\npar(mfrow=c(1,1))\nset.seed(12345)\nnpts = 1000\n\npar(mfrow=c(1, 4))\n\nr <- runif(npts, min = 0, max = 10) # Any value between 0 and 10\ntheta <- runif(npts, min = -1, max = 1) * pi # Every possible angle\ncx <- r * exp(1i * theta)\nplot(x=Re(cx), y=Im(cx), asp=1, main='Circle')\n\nr <- runif(npts, min = 0, max = 10)\ntheta <- runif(npts, min = 0.1, max = 0.25) * pi # Restricted angles\ncx <- r * exp(1i * theta)\nplot(x=Re(cx), y=Im(cx), asp=1, main='Segment')\n\nr <- runif(npts, min = 5, max = 10) # Restricted lengths\ntheta <- runif(npts, min = -1, max = 1) * pi\ncx <- r * exp(1i * theta)\nplot(x=Re(cx), y=Im(cx), asp=1, main='Annulus')\n\nr <- exp( -0.5 * runif(npts, min = 0, max = 10) ) # Exponential decay with distance\ntheta <- runif(npts, min = -1, max = 1) * pi\ncx <- r * exp(1i * theta)\nplot(x=Re(cx), y=Im(cx), asp=1, main='Gaussian')\npar(mfrow=c(1, 1))\nset.seed(12345)\nr <- runif(npts, min = 5, max = 10) # Restricted lengths\ntheta <- runif(npts, min = -1, max = 1) * pi\ncx <- r * exp(1i * theta)\nplot(x=Re(cx), y=Im(cx), asp=1, pch='.' )\npoints( x=Re(median(cx)), y=Im(median(cx)), col='red', pch=4, cex=2)\npoints( x=Re(mean(cx)), y=Im(mean(cx)), col='red', pch=3, cex=2)\npoints( x=median(Re(cx)), y=median(Im(cx)), col='blue', pch=4, cex=1)\npoints( x=mean(Re(cx)), y=mean(Im(cx)), col='blue', pch=3, cex=1)\nset.seed(12345)\nr <- runif(npts, min = 5, max = 10) # Restricted lengths\ntheta <- runif(npts, min = 0, max = 1) * pi\ncx <- r * exp(1i * theta)\nplot(x=Re(cx), y=Im(cx), asp=1, pch='.' )\npoints( x=Re(median(cx)), y=Im(median(cx)), col='red', pch=4, cex=2)\npoints( x=Re(mean(cx)), y=Im(mean(cx)), col='red', pch=3, cex=2)\npoints( x=median(Re(cx)), y=median(Im(cx)), col='blue', pch=4, cex=1)\npoints( x=mean(Re(cx)), y=mean(Im(cx)), col='blue', pch=3, cex=1)"},{"path":"image-processing.html","id":"the-fast-fourier-transform-fft-and-band-pass-filtering","chapter":"4 Image processing","heading":"The Fast Fourier Transform (FFT) and band-pass filtering","text":"FFT incredibly important algorithm allows conversion signal time frequency domains. provided base R.1D setting, idea decompose complex wave weighted sum simpler waves. create complex wave summing simple sine waves different frequencies:output FFT decomposition vector complex numbers. , plot Magnitude (modulus).observe two peaks: one 4Hz one 11Hz – matching frequencies component simple waves. Additionally, peak 4Hz twice high one 11Hz, matching coefficient twice big 4Hz 11Hz synthetic complex wave. [Additionally, note Full frequency spectrum mirrored input comprised wholly real values (imaginary).]Importantly, possible convert wave back frequency domain original time domain using inverse FFT.concept applies 2D signal (image). “Frequency” context can thought quickly pixel intensities changing small area. [, real imaginary components upon FFT decomposition.]Note changing location circle affect Magnitude (alter Phase). [Note: invariance Magnitude coordinate displacements can exploited image registration – see crossCorrelate2D function use registerImages.]image processing context, typically rearrangement Magnitude matrix – move 0Hz frequency component centre. accomplished base Matlab Python’s numpy fftshift (inverse, ifftshift). However, similar functions base R, ’ll create simple version functions :purpose fftshift make easy modify image frequency domain. instance, say care low frequencies image, mainly keep Magnitude values centre image. [similar simply applying blur image.]want high frequency …want combination low high frequency (band-pass filter)…creative choice “filter” can result different results. examples filters. Note filters formulated radial basis functions, multiplied magnitude.creative filters can also useful removing (enhancing) artefacts image.concludes brief introduction one many uses FFT algorithm.","code":"\nx <- seq(-1, 1, length.out=100) * pi\nwave1 <- sin(4 * x) #4Hz\nwave2 <- sin(11 * x) #11Hz\nwave3 <- 0.5 * wave1 + 0.25 * wave2 \n\npar(mfrow=c(3,1))\nplot(x, wave1, type='l', main='Simple wave 1')\nplot(x, wave2, type='l', main='Simple wave 2')\nplot(x, wave3, type='l', main='The complex wave')\npar(mfrow=c(1,1))\nfreq <- fft(wave3)\npar(mfrow=c(2,1))\nplot(x=seq(0, length(freq)-1, 1), y= Mod(freq), t='h', xlab = 'Frequency (Hz)', main = 'Magnitudes of FFT vector')\nplot(x=seq(0, length(freq)-1, 1), y= Mod(freq), t='h', xlab = 'Frequency (Hz)', xlim=c(0, 20), main = 'Zoomed in')\npar(mfrow=c(3,1))\nwave <- fft(freq, inverse = TRUE)\npar(mfrow=c(2,1))\nplot(x, wave3, type='l', main = 'Original wave')\nplot(x=seq(0, length(wave)-1, 1), y= Re(wave)/length(wave), t='l', xlab = 'Time (s)', main = 'Wave reconstructed from iFFT')\npar(mfrow=c(1,1))\n## Create a circle in a plane\ntoy_image <- matrix(0, nrow=201, ncol=201)\ntoy_coord <- getRasterCoords(toy_image)\ncentre <- 100+100i\nr = 30\ntoy_image[Mod(toy_coord - centre)<=r] = 1\n\n## FFT decomposition\nim_fft <- fft(toy_image) \nim_mod <- Mod(im_fft)\nim_arg <- Arg(im_fft)\n\npar(mfrow=c(1,3))\nplot( imager::as.cimg( toy_image ), interpolate = F, main = 'Original image')\nplot( imager::as.cimg( log10(1+im_mod) ), interpolate = F, main = 'FFT Log1p Magnitude')\nplot( imager::as.cimg( im_arg ), interpolate = F, main = 'FFT Phase')\npar(mfrow=c(1,1))\n## Create a circle in a plane\ntoy_image <- matrix(0, nrow=201, ncol=201)\ntoy_coord <- getRasterCoords(toy_image)\ncentre <- 50+50i\nr = 30\ntoy_image[Mod(toy_coord - centre)<=r] = 1\n\n## FFT decomposition\nim_fft <- fft(toy_image) \nim_mod <- Mod(im_fft)\nim_arg <- Arg(im_fft)\n\npar(mfrow=c(1,3))\nplot( imager::as.cimg( toy_image ), interpolate = F, main = 'Original image')\nplot( imager::as.cimg( log10(1+im_mod) ), interpolate = F, main = 'FFT Log1p Magnitude')\nplot( imager::as.cimg( im_arg ), interpolate = F, main = 'FFT Phase')\npar(mfrow=c(1,1))\nfftshift <- function(img_ff){\n  rows <- dim(img_ff)[1]    \n  cols <- dim(img_ff)[2]    \n  swap_up_down <- function(img_ff){\n    rows_half <- ceiling(rows/2)\n    return(rbind(img_ff[((rows_half+1):rows), (1:cols)], img_ff[(1:rows_half), (1:cols)]))\n  }\n  swap_left_right <- function(img_ff){\n    cols_half <- ceiling(cols/2)\n    return(cbind(img_ff[1:rows, ((cols_half+1):cols)], img_ff[1:rows, 1:cols_half]))\n  }\n  img_ff <- swap_up_down(img_ff)\n  return(swap_left_right(img_ff))\n}\n\nifftshift <- function(img_ff){\n  rows <- dim(img_ff)[1]    \n  cols <- dim(img_ff)[2]    \n  swap_up_down <- function(img_ff){\n    rows_half <- floor(rows/2)\n    return(rbind(img_ff[((rows_half+1):rows), (1:cols)], img_ff[(1:rows_half), (1:cols)]))\n  }\n  swap_left_right <- function(img_ff){\n    cols_half <- floor(cols/2)\n    return(cbind(img_ff[1:rows, ((cols_half+1):cols)], img_ff[1:rows, 1:cols_half]))\n  }\n  img_ff <- swap_left_right(img_ff)\n  return(swap_up_down(img_ff))\n}\n\npar(mfrow=c(1,3))\nplot( imager::as.cimg( toy_image ), interpolate = F, main = 'Original image')\nplot( imager::as.cimg( log10(1+im_mod) ), interpolate = F, main = 'Log1p Magnitude')\nplot( imager::as.cimg( log10(1+fftshift(im_mod)) ), interpolate = F, main = 'Magnitude with fftshift')\npar(mfrow=c(1,1))\n## FFT decomposition\nim_fft <- fft(toy_image) \nim_mod <- Mod(im_fft)\nim_arg <- Arg(im_fft)\n\n## Keep low frequencies only\ncentre_of_image = 100 + 100i\nfilter <- Mod( toy_coord - centre_of_image ) < 10\nnew_im_mod <- filter * fftshift( im_mod )\nnew_fft <- ifftshift( new_im_mod ) * exp( 1i * im_arg )\n\n## Image reconstruction\nim_recon <- fft(new_fft / length(toy_image), inverse = TRUE)\nim_recon <- Mod(im_recon)\n\npar(mfrow=c(1,4))\nplot( imager::as.cimg( toy_image ), interpolate = F, main = 'Original image')\nplot( imager::as.cimg( log10(1+fftshift(im_mod)) ), interpolate = F, main = 'Original magnitude')\nplot( imager::as.cimg( log10(1+new_im_mod) ), interpolate = F, main = 'Filtered magnitude')\nplot( imager::as.cimg( im_recon ), interpolate = F, main = 'Reconstructed image')\npar(mfrow=c(1,1))\n## FFT decomposition\nim_fft <- fft(toy_image) \nim_mod <- Mod(im_fft)\nim_arg <- Arg(im_fft)\n\n## Keep high frequencies only\ncentre_of_image = 100 + 100i\nfilter <- Mod( toy_coord - centre_of_image ) >= 10 #Invert the previous filter\nnew_im_mod <- filter * fftshift( im_mod )\nnew_fft <- ifftshift( new_im_mod ) * exp( 1i * im_arg )\n\n## Image reconstruction\nim_recon <- fft(new_fft / length(toy_image), inverse = TRUE)\nim_recon <- Mod(im_recon)\n\npar(mfrow=c(1,4))\nplot( imager::as.cimg( toy_image ), interpolate = F, main = 'Original image')\nplot( imager::as.cimg( log10(1+fftshift(im_mod)) ), interpolate = F, main = 'Original magnitude')\nplot( imager::as.cimg( log10(1+new_im_mod) ), interpolate = F, main = 'Filtered magnitude')\nplot( imager::as.cimg( im_recon ), interpolate = F, main = 'Reconstructed image')\npar(mfrow=c(1,1))\n## FFT decomposition\nim_fft <- fft(toy_image) \nim_mod <- Mod(im_fft)\nim_arg <- Arg(im_fft)\n\n## Keep a mixture of low and high frequencies\ncentre_of_image = 100 + 100i\nfilter <- ( Mod( toy_coord - centre_of_image ) >= 20 ) | ( Mod( toy_coord - centre_of_image ) < 10 )\nnew_im_mod <- filter * fftshift( im_mod )\nnew_fft <- ifftshift( new_im_mod ) * exp( 1i * im_arg )\n\n## Image reconstruction\nim_recon <- fft(new_fft / length(toy_image), inverse = TRUE)\nim_recon <- Mod(im_recon)\n\npar(mfrow=c(1,4))\nplot( imager::as.cimg( toy_image ), interpolate = F, main = 'Original image')\nplot( imager::as.cimg( log10(1+fftshift(im_mod)) ), interpolate = F, main = 'Original magnitude')\nplot( imager::as.cimg( log10(1+new_im_mod) ), interpolate = F, main = 'Filtered magnitude')\nplot( imager::as.cimg( im_recon ), interpolate = F, main = 'Reconstructed image')\npar(mfrow=c(1,1))\n# FFT decomposition\nim_fft <- fft(toy_image) \nim_mod <- Mod(im_fft)\nim_arg <- Arg(im_fft)\n\n## Filter\ncentre_of_image = 100 + 100i\nfilter <- exp( -0.5 * Mod( toy_coord - centre_of_image ) )\nnew_im_mod <- filter * fftshift( im_mod )\nnew_fft <- ifftshift( new_im_mod ) * exp( 1i * im_arg )\n\n## Image reconstruction\nim_recon <- fft(new_fft / length(toy_image), inverse = TRUE)\nim_recon <- Mod(im_recon)\n\npar(mfrow=c(1,3))\nplot( imager::as.cimg( toy_image ), interpolate = F, main = 'Original image')\nplot( imager::as.cimg( filter ), interpolate = F, main = 'Gaussian filter')\nplot( imager::as.cimg( im_recon ), interpolate = F, main = 'Reconstructed image')\npar(mfrow=c(1,1))\n# FFT decomposition\nim_fft <- fft(toy_image) \nim_mod <- Mod(im_fft)\nim_arg <- Arg(im_fft)\n\n## Filter\ncentre_of_image = 100 + 100i\nfilter <- 1 / sqrt( Mod( toy_coord - centre_of_image ) + 1 )\nnew_im_mod <- filter * fftshift( im_mod )\nnew_fft <- ifftshift( new_im_mod ) * exp( 1i * im_arg )\n\n## Image reconstruction\nim_recon <- fft(new_fft / length(toy_image), inverse = TRUE)\nim_recon <- Mod(im_recon)\n\npar(mfrow=c(1,3))\nplot( imager::as.cimg( toy_image ), interpolate = F, main = 'Original image')\nplot( imager::as.cimg( filter ), interpolate = F, main = 'Butterworth filter')\nplot( imager::as.cimg( im_recon ), interpolate = F, main = 'Reconstructed image')\npar(mfrow=c(1,1))\n# FFT decomposition\nim_fft <- fft(toy_image) \nim_mod <- Mod(im_fft)\nim_arg <- Arg(im_fft)\n\n## Filter\ncentre_of_image = 100 + 100i\nfilter <-  Mod( toy_coord - centre_of_image )^2 * -4 * pi^2\nnew_im_mod <- filter * fftshift( im_mod )\nnew_fft <- ifftshift( new_im_mod ) * exp( 1i * im_arg )\n\n## Image reconstruction\nim_recon <- fft(new_fft / length(toy_image), inverse = TRUE)\nim_recon <- Mod(im_recon)\n\npar(mfrow=c(1,3))\nplot( imager::as.cimg( toy_image ), interpolate = F, main = 'Original image')\nplot( imager::as.cimg( filter ), interpolate = F, main = 'Laplacian filter')\nplot( imager::as.cimg( im_recon ), interpolate = F, main = 'Reconstructed image')\npar(mfrow=c(1,1))\n## Create an image with artefacts\nima <- toy_image\nset.seed(12345)\nima[sample(1:(nrow(ima)-1), replace=FALSE, size=20), ] <- 1\n\n## FFT decompose\nim_fft <- fft(ima)\nim_mod <- Mod(im_fft)\nim_arg <- Arg(im_fft)\n\n## Filter\ncentre_of_image = 100 + 100i\nfilter <-  exp( -0.5 * abs( Im(toy_coord - centre_of_image) ) ) * Mod(toy_coord - centre_of_image)\nnew_im_mod <- filter * fftshift( im_mod )\nnew_fft <- ifftshift( new_im_mod ) * exp( 1i * im_arg )\n\n## Image reconstruction\nim_recon <- fft(new_fft / length(toy_image), inverse = TRUE)\nim_recon <- Mod(im_recon)\n\npar(mfrow=c(1,4))\nplot( imager::as.cimg( ima ), interpolate = F, main = 'Original image')\nplot( imager::as.cimg( log10(1+fftshift(im_mod)) ), interpolate = F, main = 'Original magnitude')\nplot( imager::as.cimg( log10(1+new_im_mod) ), interpolate = F, main = 'Filtered magnitude')\nplot( imager::as.cimg( im_recon ), interpolate = F, main = 'Reconstructed image')\npar(mfrow=c(1,1))"},{"path":"image-processing.html","id":"convolution-of-images-with-kernels","chapter":"4 Image processing","heading":"Convolution of images with kernels","text":"discussion image processing complete without mentioning use kernels. Kernels small matrices applied pixel pixel image. kernels contain weights multiplied underlying pixel intensity, summed return new value central element kernel matrix. effect weighted sum pixel intensities across small area. Choosing different kernels perform different calculations.Kernel methods flexible can executed quickly (far less computation compared approaches).instance, take Gaussian blurring (can also accomplish imager::isoblur FFT method ). Using kernel approach, calculated weighted average pixel intensities.course, choice kernel different effects: instance, see Laplace operator (used edge detection). [Note sum kernel 0, need normalize .]See https://en.wikipedia.org/wiki/Kernel_(image_processing) examples kernels uses.","code":"\n## Create image\ntoy_image <- matrix(0, nrow=21, ncol=21)\ntoy_coord <- getRasterCoords(toy_image)\ncentre <- 10+10i\nr = 5\ntoy_image[Mod(toy_coord - centre)<=r] = 1\n\nkernel <- matrix(c(\n  1, 2, 1,\n  2, 4, 2,\n  1, 1, 1\n), nrow = 3, byrow = T)\nkernel <- kernel/sum(kernel) #Normalize so sum is 1\nkernel_blur1 <- imager::convolve( imager::as.cimg(toy_image), imager::as.cimg(kernel) )\n\nkernel <- matrix(c(\n  1, 4, 6, 4, 1,\n  4, 16, 24, 16, 4,\n  6, 24, 36, 24, 6,\n  4, 16, 24, 16, 4,\n  1, 4, 6, 4, 1\n), nrow = 5, byrow = T)\nkernel <- kernel/sum(kernel) #Normalize so sum is 1\nkernel_blur2 <- imager::convolve( imager::as.cimg(toy_image), imager::as.cimg(kernel) )\n\npar(mfrow=c(1,3))\nplot( imager::as.cimg( toy_image ), interpolate = F, main = 'Original image')\nplot( imager::as.cimg( kernel_blur1 ), interpolate = F, main = 'Kernel blur (3x3)')\nplot( imager::as.cimg( kernel_blur2 ), interpolate = F, main = 'Kernel blur (5x5)')\npar(mfrow=c(1,1))\nkernel <- matrix(c(\n  -1, -1, -1,\n  -1, 8, -1,\n  -1, -1, -1\n), nrow = 3, byrow = T)\nkernel_blur1 <- imager::convolve( imager::as.cimg(toy_image), imager::as.cimg(kernel) )\n\npar(mfrow=c(1,2))\nplot( imager::as.cimg( toy_image ), interpolate = F, main = 'Original image')\nplot( imager::as.cimg( kernel_blur1 ), interpolate = F, main = 'Laplace operator')\npar(mfrow=c(1,1))"},{"path":"image-processing.html","id":"combining-building-blocks","chapter":"4 Image processing","heading":"4.4 Combining building blocks","text":"Using building blocks , relevant functions {imager} {EBImage}, users can create complex image processing pipelines. example composite function imLowPass created using combination imNormalise, image blurring, imAutoBrighten.ALWAYS plot check image processing altered image!","code":"\nmasmr::imLowPass## function (im, smallBlur, currentIteration, ...) \n## {\n##     if (!missing(currentIteration)) {\n##         message(currentIteration, appendLF = F)\n##     }\n##     if (missing(smallBlur)) {\n##         smallBlur = 1\n##     }\n##     background <- imNormalise(im, ...) == 0\n##     imblur <- array(imager::isoblur(suppressWarnings(imager::as.cimg(im)), \n##         smallBlur), dim = dim(im))\n##     lowthresh <- median(imblur[background])\n##     hithresh <- median(imblur[!background & (imblur > lowthresh)])\n##     if (((lowthresh > 0) & (hithresh < 1) & (lowthresh < hithresh) & \n##         !is.na(lowthresh) & !is.na(hithresh))) {\n##         norm <- imAutoBrighten(imblur, floorVal = lowthresh, \n##             ceilVal = hithresh)\n##     }\n##     else {\n##         warning(paste0(\"Skipping imAutoBrighten because of invalid floorVal (\", \n##             lowthresh, \") and/or ceilVal (\", hithresh, \")...\"))\n##         norm <- imblur\n##     }\n##     norm <- imNormalise(norm)\n##     return(norm)\n## }\n## <bytecode: 0x00000242cc04f948>\n## <environment: namespace:masmr>\nnorm <- imLowPass(im, floorVal = params$brightness_min[1], ceilVal = params$brightness_max[1] )\npar(mfrow=c(1,2))\nplot( imager::as.cimg(norm), main = 'Low pass' )## Warning in as.cimg.array(norm): Assuming third dimension corresponds to time/depth\nhist( norm, breaks=1000, main = 'Low pass', xlab='Intensities', ylab='N pixels' )\npar(mfrow=c(1,1))"},{"path":"image-processing.html","id":"building-your-own-function-an-example","chapter":"4 Image processing","heading":"4.5 Building your own function: an example","text":"Users strongly encouraged experiment provided image processing functions create image processing pipelines necessary. , provide example custom function may built.Say dissatisfied current default masking function (imForMask), whose purpose flag pixels suspect spot , restrictive (.e. flagging strongest signals).First, let’s look imForMask . , see takes single image im …Low pass filtering image imLowPass function: returning lowpassCalculates determinant Hessian (imNormalise %>% imHessianDeterminant %>% isoblur): returning dethessbCalculates Laplacian Gaussian (imNormalise %>% imLaplacianOfGaussian): returning LoGMasking LoG dethessb identifying appropriate thresholds (findThreshold)Scoring pixels 0 1 using product lowpass LoG, saturated pixels (norm==1 im==1) set max scoreFlagging saturated pixels (im==1), pixels superthreshold LoG, pixels superthreshold dethessb: returning lab (1 yes three criteria, otherwise 0)Finding threshold scores calculated step (5) separate 1 0 lab step 6: returning maskSize filter mask remove masks smaller minBlobSize pixelsNext, let’s create new mask function permissive flag pixels. myCustomMask function created copying editing default imForMask function . Briefly, new function replaces steps 5-7 default imForMask function union multiple masks.[Note: use ellipsis (...) allow passing arguments myCustomMask functions within myCustomMask: e.g. imLaplacianOfGaussian, imHessianDeterminant etc.]satisfied custom function, returning intermediate images can skipped:Voila! new custom masking function.explained create custom function, discuss custom functions can looped image list.","code":"\n## The original image is a bit too dim for visualisation: but will provide here for completeness\nplot(imager::as.cimg( imList[[1]][1000:1500, 1000:1500, 1] ), main='Original')\npar(mfrow=c(1,2))\nplot(imager::as.cimg( imList[[1]][1000:1500, 1000:1500, 1]^0.1 ), main='Original (brightened)')\nplot(imager::as.cimg( imForMask(imList[[1]])[1000:1500, 1000:1500, 1] ), main='Default mask')\npar(mfrow=c(1,1))\nmasmr::imForMask## function (im, smallBlur, minBlobSize, currentIteration, ...) \n## {\n##     if (!missing(currentIteration)) {\n##         message(currentIteration, appendLF = F)\n##     }\n##     if (missing(smallBlur)) {\n##         smallBlur = 1\n##     }\n##     if (missing(minBlobSize)) {\n##         minBlobSize = 9\n##     }\n##     norm <- imNormalise(im, ...)\n##     lowpass <- imLowPass(norm, ...)\n##     dethess <- imHessianDeterminant(norm, ...)\n##     dethess <- imNormalise(dethess)\n##     dethessb <- array(imager::isoblur(suppressWarnings(imager::as.cimg(dethess)), \n##         smallBlur), dim = dim(im))\n##     vals <- dethessb[dethessb > quantile(dethessb, 0.95)]\n##     dethessbFloor <- findThreshold(vals, method = thresh_Elbow, \n##         ...)\n##     LoG <- imLaplacianOfGaussian(norm, ...)\n##     LoGthresh <- findThreshold(LoG[LoG > 0], method = thresh_Elbow, \n##         ...)\n##     vals <- imNormalise(lowpass * imNormalise(LoG, floorVal = LoGthresh, \n##         ceilVal = max(LoG)))\n##     vals[((im >= 1) + (norm >= 1)) > 0] <- 1\n##     lab <- ((LoG > LoGthresh) + (dethessb > dethessbFloor) + \n##         (im == 1)) > 0\n##     thresh <- findThreshold(vals, method = thresh_Quantile, labels = lab, \n##         ...)\n##     mask <- vals > thresh\n##     labmask <- EBImage::bwlabel(mask)\n##     toosmall <- which(tabulate(labmask) < minBlobSize)\n##     mask[labmask %in% toosmall] <- F\n##     return(mask)\n## }\n## <bytecode: 0x000002424e45c7b0>\n## <environment: namespace:masmr>\nmyCustomMask <- function (im, smallBlur, minBlobSize, currentIteration, ...){\n    if (!missing(currentIteration)) {\n        message(currentIteration, appendLF = F)\n    }\n    if (missing(smallBlur)) {\n        smallBlur = 1\n    }\n    if (missing(minBlobSize)) {\n        minBlobSize = 9\n    }\n    \n    ## Old code: Calculate scores per pixel as per the default imForMask function\n    norm <- imNormalise(im, ...)\n    lowpass <- imLowPass(im, ...)\n    dethess <- imHessianDeterminant(norm, ...)\n    dethess <- imNormalise(dethess)\n    dethessb <- array(imager::isoblur(suppressWarnings(imager::as.cimg(dethess)), \n        smallBlur), dim = dim(im))\n    vals <- dethessb[dethessb > quantile(dethessb, 0.95)]\n    dethessbFloor <- findThreshold(vals, method = thresh_Elbow, \n        ...)\n    LoG <- imLaplacianOfGaussian(norm, ...)\n    LoGthresh <- findThreshold(LoG[LoG > 0], method = thresh_Elbow, \n        ...)\n    \n    ## New code: also get LoG values for the lowpass image\n    LoGLowPass <- imLaplacianOfGaussian(norm * lowpass)\n    LoGthreshLowPass <- findThreshold(LoG[LoG > 0], method = thresh_Elbow, ...)\n    \n    ## New code: Union of masks\n    mask <- \n      (LoG>LoGthresh) +               #LoG of original image above threshold\n      (LoGLowPass>LoGthreshLowPass) + #LoG of lowpass image above threshold\n      (dethessb>dethessbFloor) +      #detHess above threshold\n      (im==1)                         #Saturated pixels\n    mask <- mask > 0                  #Inclusive Or\n    allmask <- mask\n    \n    ## Old code: Filter out masks that are too small\n    labmask <- EBImage::bwlabel(mask)\n    toosmall <- which(tabulate(labmask) < minBlobSize)\n    mask[labmask %in% toosmall] <- F\n    final <- mask\n    \n    ## If function ready, just return final\n    # return(final)\n    \n    ## If troubleshooting, return all intermediate images\n    processedImages <- list(\n      'Norm' = norm,\n      'LowPass' = lowpass,\n      'detHess' = dethessb,\n      'detHess masked' = dethessb>dethessbFloor,\n      'LoG' = LoG,\n      'LoG masked' = LoG>LoGthresh,\n      'LowPass LoG' = LoGLowPass,\n      'LowPass LoG masked' = LoGLowPass>LoGthreshLowPass,\n      'All masks' = allmask,\n      'Masks after size filter' = mask\n    )\n    return( processedImages )\n}\n\nprocessedImages <- myCustomMask( imList[[1]] )\n\npar(mfrow=c(5,2))\nfor( imMetricName in names(processedImages) ){\n  plot(imager::as.cimg( processedImages[[imMetricName]][1000:1500, 1000:1500, 1] ), main = toupper(imMetricName) )\n}\npar(mfrow=c(1,1))\nmyCustomMask <- function (im, smallBlur, minBlobSize, currentIteration, ...){\n    if (!missing(currentIteration)) {\n        message(currentIteration, appendLF = F)\n    }\n    if (missing(smallBlur)) {\n        smallBlur = 1\n    }\n    if (missing(minBlobSize)) {\n        minBlobSize = 9\n    }\n    \n    ## Calculate scores per pixel as per the default imForMask function\n    norm <- imNormalise(im, ...)\n    lowpass <- imLowPass(im, ...)\n    dethess <- imHessianDeterminant(norm, ...)\n    dethess <- imNormalise(dethess)\n    dethessb <- array(imager::isoblur(suppressWarnings(imager::as.cimg(dethess)), \n        smallBlur), dim = dim(im))\n    vals <- dethessb[dethessb > quantile(dethessb, 0.95)]\n    dethessbFloor <- findThreshold(vals, method = thresh_Elbow, \n        ...)\n    LoG <- imLaplacianOfGaussian(norm, ...)\n    LoGthresh <- findThreshold(LoG[LoG > 0], method = thresh_Elbow, \n        ...)\n    \n    ## New: also get LoG values for the lowpass image\n    LoGLowPass <- imLaplacianOfGaussian(norm * lowpass)\n    LoGthreshLowPass <- findThreshold(LoG[LoG > 0], method = thresh_Elbow, ...)\n    \n    ## Union of masks\n    mask <- \n      (LoG>LoGthresh) +               #LoG of original image above threshold\n      (LoGLowPass>LoGthreshLowPass) + #LoG of lowpass image above threshold\n      (dethessb>dethessbFloor) +      #detHess above threshold\n      (im==1)                         #Saturated pixels\n    mask <- mask > 0                  #Inclusive Or\n    allmask <- mask\n    \n    ## Filter out masks that are too small\n    labmask <- EBImage::bwlabel(mask)\n    toosmall <- which(tabulate(labmask) < minBlobSize)\n    mask[labmask %in% toosmall] <- F\n    final <- mask\n    \n    ## If function ready, just return final\n    return(final)\n    \n    ## If troubleshooting, return all intermediate images\n    # processedImages <- list(\n    #   'Norm' = norm,\n    #   'LowPass' = lowpass,\n    #   'detHess' = dethessb,\n    #   'detHess masked' = dethessb>dethessbFloor,\n    #   'LoG' = LoG,\n    #   'LoG masked' = LoG>LoGthresh,\n    #   'LowPass LoG' = LoGLowPass,\n    #   'LowPass LoG masked' = LoGLowPass>LoGthreshLowPass,\n    #   'All masks' = allmask,\n    #   'Masks after size filter' = mask\n    # )\n    # return( processedImages )\n}\npar(mfrow=c(1,2))\nplot(imager::as.cimg( imList[[1]][1000:1500, 1000:1500, 1]^0.1 ), main='Original (brightened)')\nplot(imager::as.cimg( myCustomMask(imList[[1]])[1000:1500, 1000:1500, 1] ), main='Custom mask')\npar(mfrow=c(1,1))"},{"path":"image-processing.html","id":"feeding-image-processing-pipelines-into-getimagemetrics","chapter":"4 Image processing","heading":"4.6 Feeding image processing pipelines into getImageMetrics","text":"listing looping functions named list imageFunctions (much like done getAnchorParams), users can perform different types image processing using getImageMetrics function. result new environment object (imMetrics) houses image lists processed different ways. default, following image processing performed:ORIG: unprocessed images.NORM: images min-max normalised.COARSE: low-pass images, optimised separate foreground background.DECODE: images optimised decoding.MASK: images pixels worth bringing forward decoding masked TRUE.ALWAYS plot check image processing altered image!Users can , visualise function performs one FOV. satisfied, custom function can looped images imList getImageMetrics:important note imMetrics$MASK determine pixels brought forwards decoding later consolidateImageMetrics function; decoding performed imMetrics$DECODE. DECODE MASK metrics thus image processing pipelines users focus optimising.users want decode whole image (may memory intensive), removing MASK imMetrics (example ), creating imMetrics$MASK TRUE every pixel work. , spotcalling depend DECODE images.Experiment find works dataset. Don’t forget make use functions like filterDF spotcall_troubleshootPlots help troubleshoot (see Chapter 3).Users encouraged optimise image processing pipelines one FOV, applying pipelines FOVs.","code":"\ngetImageMetrics( \n  imList,\n  imageFunctions = list(\n    'ORIG' = imReturn,\n    'NORM' = imWinsorIntensities,\n    'COARSE' = imLowPass,\n    'DECODE' = imForDecode,\n    'MASK' = imForMask\n  ))\npar(mfrow=c(2,3))\nfor( imMetricName in ls(imMetrics) ){\n  plot(imager::as.cimg( imMetrics[[imMetricName]][[1]][1000:1500, 1000:1500, 1] ), main = imMetricName)\n}\npar(mfrow=c(1,1))\nuserCustomFunction <- function( im ){\n  ## User to decide on how they want the image to be processed\n  ...\n}\n\n## Loop the custom function across all images\ngetImageMetrics( \n  imList,\n  imageFunctions = list(\n    'ORIG' = imReturn,\n    'NORM' = imWinsorIntensities,\n    'COARSE' = imLowPass,\n    'DECODE' = imForDecode,\n    'MASK' = imForMask,\n    'CUSTOM' = userCustomFunction #New function  (or replace one of the above with your new function)\n  ))\nmyCustomMask <- function(im){\n  return( im > -Inf ) #Return TRUE for every pixel\n}\ngetImageMetrics( \n  imList,\n  imageFunctions = list(\n    'ORIG' = imReturn,\n    'NORM' = imWinsorIntensities,\n    'COARSE' = imLowPass,\n    'DECODE' = imForDecode,\n    'MASK' = myCustomMask #User replacing the mask function\n  ))\n\n## Alternatively, users can remove the MASK\nimMetrics$MASK <- NULL"},{"path":"cell-segmentation.html","id":"cell-segmentation","chapter":"5 Cell segmentation","heading":"5 Cell segmentation","text":"Cell / nuclei segmentation task identifying cells / nuclei appropriate image (referring cell nuclei segmentation interchangeably ). currently support two popular Python-based models: {cellpose} (Stringer et al. 2021) {stardist} (Schmidt et al. 2018; Weigert Schmidt 2022). [hope provide wholly R-based options future.]cell segmentation performed DAPI images, can performed parallel spotcalling.","code":"\nlibrary(masmr)\nlibrary(ggplot2)"},{"path":"cell-segmentation.html","id":"pre-processing-2","chapter":"5 Cell segmentation","heading":"5.1 Pre-processing","text":"","code":""},{"path":"cell-segmentation.html","id":"establishing-parameters-1","chapter":"5 Cell segmentation","heading":"5.1.1 Establishing parameters","text":"Similar spotcalling, first need establish parameters. code used spotcalling can repeated .relevance cell segmentation specifically pythonLocation dapiDir parameters:dapiDir: location DAPI images. [Technically, cell-based imaging likely work – just DAPI – long compatible cell segmentation models.]pythonLocation: location user’s Python environment. Python environment contain packages necessary run cell segmentation model choice.Details setting Python environment beyond scope book. Briefly, exist various tools (e.g. miniconda, anaconda, miniforge) allow users create Python environment installing necessary software. interface environment reticulate. series commands set Python environment called scipyenv compatible {stardist} {cellpose}. Users take note environment created, provide location folder pythonLocation.Additionally, similar spotcalling, also readImageMetaData, though time DAPI images specifically. decoding, warnings codebook column names matching can safely ignored., adds additional metadata params object, albeit time DAPI images specifically:","code":"\ndata_dir = 'C:/Users/kwaje/Downloads/JIN_SIM/20190718_WK_T2_a_B2_R8_12_d50/'\nestablishParams(\n  \n  ## User to fill in\n  imageDirs = paste0(data_dir, 'S10/'),\n  imageFormat = '.ome.tif',\n  outDir = 'C:/Users/kwaje/Downloads/JYOUT/',\n  codebookFileName = list.files(paste0(data_dir,'codebook/'),pattern='codebook',full.names = TRUE),\n  dapiDir = paste0(data_dir, 'DAPI_1/'),\n  \n  ## Will attempt automatic fill\n  # metaFormat = '.ome.tif',\n  # dapiFormat = '.ome.tif',\n  codebookColumnNames = paste0(rep(c(0:3),4),'_',rep(c('cy3','alexa594','cy5','cy7'),each=4)),\n  pythonLocation = 'C:/Users/kwaje/AppData/Local/miniforge3/envs/scipyenv/',\n  \n  ## Automatically filled\n  # seed = 12345,\n  verbose = FALSE,\n  # resumeMode = TRUE,\n  \n  ## Optional (but recommended for QC checks)\n  fpkmFileName = paste0(data_dir, \"FPKM_data/Jin_FPKMData_B.tsv\"),\n  nProbesFileName = paste0(data_dir, \"ProbesPerGene.csv\")\n)## Assuming .ome.tif is extension for meta files...conda create -n scipyenv python=3.9 notebook pandas numpy=1.26.4\nconda activate scipyenv\nconda install pytorch=1.12.1 cudatoolkit=10.2 -c pytorch #1.12.1 is the earliest mps is supported\npip install cellpose==3.0.11\npip install tensorflow==2.17.0\npip install stardist==0.9.1\nreadImageMetaData( 'dapi_dir' )## Warning in readImageMetaData(\"dapi_dir\"): Assuming this data has been acquired by Triton## Warning in readImageMetaData(\"dapi_dir\"): bit_name not matching codebookColumnNames: either edit GLOBALCOORD.csv or params$codebook_colnames (ignore\n## this warning if codebook not needed, e.g. DAPI)## Warning in readImageMetaData(\"dapi_dir\"): Updating params$fov_names## Warning in readImageMetaData(\"dapi_dir\"): Unsuccessful attempt at correcting placeholder codebook column names (params$codebook_colnames)\nprint( params$resolutions )## $per_pixel_microns\n## [1] \"0.0706\" \"0.0706\"\n## \n## $xydimensions_pixels\n## [1] \"2960\" \"2960\"\n## \n## $xydimensions_microns\n## [1] \"208.976\" \"208.976\"\n## \n## $channel_order\n## [1] \"dapi\"\n## \n## $fov_names\n##   [1] \"MMStack_1-Pos_000_000\" \"MMStack_1-Pos_001_000\" \"MMStack_1-Pos_002_000\" \"MMStack_1-Pos_003_000\" \"MMStack_1-Pos_004_000\" \"MMStack_1-Pos_005_000\"\n##   [7] \"MMStack_1-Pos_006_000\" \"MMStack_1-Pos_007_000\" \"MMStack_1-Pos_008_000\" \"MMStack_1-Pos_009_000\" \"MMStack_1-Pos_009_001\" \"MMStack_1-Pos_008_001\"\n##  [13] \"MMStack_1-Pos_007_001\" \"MMStack_1-Pos_006_001\" \"MMStack_1-Pos_005_001\" \"MMStack_1-Pos_004_001\" \"MMStack_1-Pos_003_001\" \"MMStack_1-Pos_002_001\"\n##  [19] \"MMStack_1-Pos_001_001\" \"MMStack_1-Pos_000_001\" \"MMStack_1-Pos_000_002\" \"MMStack_1-Pos_001_002\" \"MMStack_1-Pos_002_002\" \"MMStack_1-Pos_003_002\"\n##  [25] \"MMStack_1-Pos_004_002\" \"MMStack_1-Pos_005_002\" \"MMStack_1-Pos_006_002\" \"MMStack_1-Pos_007_002\" \"MMStack_1-Pos_008_002\" \"MMStack_1-Pos_009_002\"\n##  [31] \"MMStack_1-Pos_009_003\" \"MMStack_1-Pos_008_003\" \"MMStack_1-Pos_007_003\" \"MMStack_1-Pos_006_003\" \"MMStack_1-Pos_005_003\" \"MMStack_1-Pos_004_003\"\n##  [37] \"MMStack_1-Pos_003_003\" \"MMStack_1-Pos_002_003\" \"MMStack_1-Pos_001_003\" \"MMStack_1-Pos_000_003\" \"MMStack_1-Pos_000_004\" \"MMStack_1-Pos_001_004\"\n##  [43] \"MMStack_1-Pos_002_004\" \"MMStack_1-Pos_003_004\" \"MMStack_1-Pos_004_004\" \"MMStack_1-Pos_005_004\" \"MMStack_1-Pos_006_004\" \"MMStack_1-Pos_007_004\"\n##  [49] \"MMStack_1-Pos_008_004\" \"MMStack_1-Pos_009_004\" \"MMStack_1-Pos_009_005\" \"MMStack_1-Pos_008_005\" \"MMStack_1-Pos_007_005\" \"MMStack_1-Pos_006_005\"\n##  [55] \"MMStack_1-Pos_005_005\" \"MMStack_1-Pos_004_005\" \"MMStack_1-Pos_003_005\" \"MMStack_1-Pos_002_005\" \"MMStack_1-Pos_001_005\" \"MMStack_1-Pos_000_005\"\n##  [61] \"MMStack_1-Pos_000_006\" \"MMStack_1-Pos_001_006\" \"MMStack_1-Pos_002_006\" \"MMStack_1-Pos_003_006\" \"MMStack_1-Pos_004_006\" \"MMStack_1-Pos_005_006\"\n##  [67] \"MMStack_1-Pos_006_006\" \"MMStack_1-Pos_007_006\" \"MMStack_1-Pos_008_006\" \"MMStack_1-Pos_009_006\" \"MMStack_1-Pos_009_007\" \"MMStack_1-Pos_008_007\"\n##  [73] \"MMStack_1-Pos_007_007\" \"MMStack_1-Pos_006_007\" \"MMStack_1-Pos_005_007\" \"MMStack_1-Pos_004_007\" \"MMStack_1-Pos_003_007\" \"MMStack_1-Pos_002_007\"\n##  [79] \"MMStack_1-Pos_001_007\" \"MMStack_1-Pos_000_007\" \"MMStack_1-Pos_000_008\" \"MMStack_1-Pos_001_008\" \"MMStack_1-Pos_002_008\" \"MMStack_1-Pos_003_008\"\n##  [85] \"MMStack_1-Pos_004_008\" \"MMStack_1-Pos_005_008\" \"MMStack_1-Pos_006_008\" \"MMStack_1-Pos_007_008\" \"MMStack_1-Pos_008_008\" \"MMStack_1-Pos_009_008\"\n##  [91] \"MMStack_1-Pos_009_009\" \"MMStack_1-Pos_008_009\" \"MMStack_1-Pos_007_009\" \"MMStack_1-Pos_006_009\" \"MMStack_1-Pos_005_009\" \"MMStack_1-Pos_004_009\"\n##  [97] \"MMStack_1-Pos_003_009\" \"MMStack_1-Pos_002_009\" \"MMStack_1-Pos_001_009\" \"MMStack_1-Pos_000_009\"\n## \n## $zslices\n## [1] \"1\"\nknitr::kable( head( params$global_coords ), format = 'html', booktabs = TRUE )"},{"path":"cell-segmentation.html","id":"establishing-the-cell-segmentation-model","chapter":"5 Cell segmentation","heading":"5.1.2 Establishing the cell segmentation model","text":"Unique cell segmentation script, users must load desired cell segmentation model environment. accomplished establishCellSegModel function, returns new environment object called cellSeg.parameters specified, nuclei model {cellpose} loaded. [showcase loading different models later chapter.] Additionally, GPU acceleration turned default – users able access computer’s GPU may turn time saving.cellSeg environment keeps track model loaded outputs expected model. Users may load multiple models wish increase run time: models cellSeg run DAPI images. , single model CELLPOSE, within model expected outputs.","code":"\nestablishCellSegModel()## \n## Preparing cell segmentation model(s)...## Cellpose packaged model...\nls(cellSeg)## [1] \"CELLPOSE\"\ncellSeg$CELLPOSE## $model\n## <cellpose.models.CellposeModel object at 0x00000241BF7D6B20>\n## \n## $outputs\n## [1] \"masks\"  \"flows\"  \"styles\" \"diams\""},{"path":"cell-segmentation.html","id":"running-cell-segmentation","chapter":"5 Cell segmentation","heading":"5.2 Running cell segmentation","text":"memory management, recommended FOVs processed individual tiles. , read specific FOV (recommended, save current FOV params$current_fov). can use readImage specific file, – know FOV want – readImageList.NOTE: may complicated Z-stacks multiple channels. Process accordingly thatimis single matrix DAPI channel.","code":"\nparams$current_fov <- params$fov_names[38]\nim <- readImageList( params$current_fov )[[1]] #List of 1\nplot(imager::as.cimg(im))## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth"},{"path":"cell-segmentation.html","id":"running-segmentation-model","chapter":"5 Cell segmentation","heading":"5.3 Running segmentation model","text":"necessary parameters established, ready run cell segmentation model runCellSegModel function. image processing DAPI images generally necessary models tend -built image processing functions. However, found modifying image parameters can influence cell segmentation; detailed discussion provided .","code":""},{"path":"cell-segmentation.html","id":"cellpose","chapter":"5 Cell segmentation","heading":"5.3.1 Cellpose","text":"{cellpose} default choice owing applicable nuclei cellular segmentation. deep-learning based segmentation model trained variety image types including DAPI images alone (nuclei), multi-channel images nuclei cell boundary stains (cyto, cyto2, cyto3).example run model within {masmr} shown . [default, mask output returned; can turned setting masksOnly FALSE.]default nuclei model called {cellpose} seem working well images. several ways troubleshoot:","code":"\ncellMask <- runCellSegModel(im, masksOnly = TRUE)\ndf <- as.data.frame(imager::as.cimg(cellMask))\nggplot() +\n  geom_raster( data = as.data.frame(imager::as.cimg(im)), \n               aes(x=x, y=y, fill=value) ) +\n  scale_fill_gradient(low='black', high='white') +\n  geom_point( data=df[df$value>0,], \n              aes(x=x, y=y, colour=factor(value)),\n              shape = '.') +\n  scale_colour_viridis_d( option='turbo' ) +\n  theme_void( base_size = 14 ) +\n  scale_y_reverse() +\n  coord_fixed() +\n  theme(legend.position = 'none')"},{"path":"cell-segmentation.html","id":"dilating-existing-masks","chapter":"5 Cell segmentation","heading":"Dilating existing masks","text":"issue cell masks accurate, small – lower number counts assigned cell – one quick solution dilate existing masks.several ways . example quickly {imager} – dependency {masmr}. [Possible alternatives: Voronoi tessellation, setting radius threshold cell segmentation mask centre.]Note: choice size parameter imager::dilate_square slightly non-intuitive: (1) input values rounded nearest integer, (2) odd numbers provide isotropic dilations (even values dilate bottom right).","code":"\ndilation_sizes <- c(0L, 50L)\nplotList <- list()\nfor(i in 1:length(dilation_sizes)){\n  \n  ## Dilate a cellMask by a certain size\n  original_cellMask <- imager::as.cimg(cellMask)\n  dilated_cellMask <- imager::dilate_square(original_cellMask, size = dilation_sizes[i] )\n  \n  ## Plot the masks atop the original image\n  df <- as.data.frame(dilated_cellMask)\n  plotList[[i]] <- ggplot() +\n    geom_raster( data = as.data.frame(imager::as.cimg(im)), \n                 aes(x=x, y=y, fill=value) ) +\n    scale_fill_gradient(low='black', high='white') +\n    geom_point( data=df[df$value>0,], \n                aes(x=x, y=y, colour=factor(value)),\n                shape = '.') +\n    scale_colour_viridis_d( option='turbo' ) +\n    theme_void( base_size = 14 ) +\n    scale_y_reverse() +\n    coord_fixed() +\n    theme(legend.position = 'none') +\n    ggtitle( paste0('Dilate size: ', dilation_sizes[i] ))\n}\ncowplot::plot_grid(plotlist = plotList)\npretendImage <- imager::as.cimg( array(0, dim=c(9, 9)) )\npretendImage[5,5] <- 1\ndilation_sizes <- c(0, 1, 2, 3, 3.9, 4, 5, 6, 7)\npar(mfrow=c(3,3))\nfor( i in 1:length(dilation_sizes) ){\n  plot( imager::dilate_square(pretendImage, size=dilation_sizes[i]), interpolate=F,\n        main = paste0('Size: ', dilation_sizes[i]) )\n}\npar(mfrow=c(1,1))"},{"path":"cell-segmentation.html","id":"altering-model-parameters","chapter":"5 Cell segmentation","heading":"Altering model parameters","text":"default evaluation {cellpose} assumes diameter 30 pixels. wish increase value, can accomplished adding model parameters runCellSegModel. , increase diameter parameter (specific {cellpose} model) 50. [masksOnly default TRUE, reproduce parameter .]","code":"\ncellMask <- runCellSegModel(im, diameter = 50)\ndf <- as.data.frame(imager::as.cimg(cellMask))\nggplot() +\n  geom_raster( data = as.data.frame(imager::as.cimg(im)), \n               aes(x=x, y=y, fill=value) ) +\n  scale_fill_gradient(low='black', high='white') +\n  geom_point( data=df[df$value>0,], \n              aes(x=x, y=y, colour=factor(value)),\n              shape = '.') +\n  scale_colour_viridis_d( option='turbo' ) +\n  theme_void( base_size = 14 ) +\n  scale_y_reverse() +\n  coord_fixed() +\n  theme(legend.position = 'none')## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth"},{"path":"cell-segmentation.html","id":"image-processing-1","chapter":"5 Cell segmentation","heading":"Image processing","text":"models, altering intensity values (e.g. brightening) can influence model performance. {cellpose}, model generally robust additional image processing. [Compare {stardist} .]","code":"\nnorm <- im^0.5\npar(mfrow=c(1,2))\nplot(imager::as.cimg(im), main = 'Original image')## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth\nplot(imager::as.cimg(norm), main = 'Brightened image')## Warning in as.cimg.array(norm): Assuming third dimension corresponds to time/depth\npar(mfrow=c(1,1))\n\ncellMask <- runCellSegModel( norm )\ndf <- as.data.frame(imager::as.cimg(cellMask))\nggplot() +\n  geom_raster( data = as.data.frame(imager::as.cimg(im)), \n               aes(x=x, y=y, fill=value) ) +\n  scale_fill_gradient(low='black', high='white') +\n  geom_point( data=df[df$value>0,], \n              aes(x=x, y=y, colour=factor(value)),\n              shape = '.') +\n  scale_colour_viridis_d( option='turbo' ) +\n  theme_void( base_size = 14 ) +\n  scale_y_reverse() +\n  coord_fixed() +\n  theme(legend.position = 'none')## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth"},{"path":"cell-segmentation.html","id":"loading-a-retrained-model","chapter":"5 Cell segmentation","heading":"Loading a retrained model","text":"users resources retrain default {cellpose} model (Pachitariu Stringer 2022), retrained model can loaded lieu default models. , user’s model can specified establishCellSegModel.[Model retraining beyond scope book. Users encouraged look documentation {cellpose}.]","code":"\nestablishCellSegModel(\n  cellposePreTrainedModel =\n    'C:/Users/kwaje/OneDrive - A STAR/Documents/Workplace/Liu_Connect/Code/jinyue_cellpose_models/CP_model3_newB4_800epoch_lr0pt01_FINAL'\n)## \n## Preparing cell segmentation model(s)...## User-pretrained Cellpose model...\ncellMask <- runCellSegModel(im)\ndf <- as.data.frame(imager::as.cimg(cellMask))\nggplot() +\n  geom_raster( data = as.data.frame(imager::as.cimg(im)), \n               aes(x=x, y=y, fill=value) ) +\n  scale_fill_gradient(low='black', high='white') +\n  geom_point( data=df[df$value>0,], \n              aes(x=x, y=y, colour=factor(value)),\n              shape = '.') +\n  scale_colour_viridis_d( option='turbo' ) +\n  theme_void( base_size = 14 ) +\n  scale_y_reverse() +\n  coord_fixed() +\n  theme(legend.position = 'none')## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth"},{"path":"cell-segmentation.html","id":"stardist","chapter":"5 Cell segmentation","heading":"5.3.2 Stardist","text":"alternative nuclei segmentation use {stardist}: deep-learning segmentation model relies star-convex polygons. model trained DAPI images (2D_versatile_fluo), H&E stains (2D_versatile_he). typically faster {cellpose}, allowing looping multiple hyperparameters – users interested.[Tip: Windows users reported running [WinError 1314] required privilege held client error attempting load {stardist}. get around problem, manually unzip downloaded model (file location reported error message). reason, 2D_versatile_fluo.zip erroneously unzipped 2D_versatile_fluo_extracted instead 2D_versatile_fluo cases.]{cellpose}, various ways troubleshoot base {stardist} performance.Like {cellpose}, users can tweak {stardist} model parameters runCellSegModel. instance, decreasing prob_thresh (default: 0.48) increases sensitivity.also found {stardist} sensitive brightness values / image processing {cellpose}. instance, brightening image greatly impairs nuclei detection:darkening image greatly increases sensitivity:Given sensitivity, relatively faster speed {stardist}, users might wish try different image processing prior cell segmentation. can accomplished . Note runCellSegModel accepts single image matrix, list images. [achievable {cellpose} desired, users aware longer runtime.]summarise list masks single mask matrix, provide consolidateCellSegMasks function. works overlaying masks list, accepting image pixels masked least \\(n\\) times. default, \\(n = 1\\), pixel masked least , brought forwards.Increasing \\(n\\) means pixels need masked , thus decreases number masks identified. shows \\(n = 2\\):","code":"\nestablishCellSegModel( 'stardist' )## \n## Preparing cell segmentation model(s)...## Stardist packaged model...## Found model '2D_versatile_fluo' for 'StarDist2D'.\n## Loading network weights from 'weights_best.h5'.\n## Loading thresholds from 'thresholds.json'.\n## Using default values: prob_thresh=0.479071, nms_thresh=0.3.\ncellMask <- runCellSegModel(im)\ndf <- as.data.frame(imager::as.cimg(cellMask))\nggplot() +\n  geom_raster( data = as.data.frame(imager::as.cimg(im)), \n               aes(x=x, y=y, fill=value) ) +\n  scale_fill_gradient(low='black', high='white') +\n  geom_point( data=df[df$value>0,], \n              aes(x=x, y=y, colour=factor(value)),\n              shape = '.') +\n  scale_colour_viridis_d( option='turbo' ) +\n  theme_void( base_size = 14 ) +\n  scale_y_reverse() +\n  coord_fixed() +\n  theme(legend.position = 'none')## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth\ncellMask <- runCellSegModel(im, prob_thresh = 0.1)\ndf <- as.data.frame(imager::as.cimg(cellMask))\nggplot() +\n  geom_raster( data = as.data.frame(imager::as.cimg(im)), \n               aes(x=x, y=y, fill=value) ) +\n  scale_fill_gradient(low='black', high='white') +\n  geom_point( data=df[df$value>0,], \n              aes(x=x, y=y, colour=factor(value)),\n              shape = '.') +\n  scale_colour_viridis_d( option='turbo' ) +\n  theme_void( base_size = 14 ) +\n  scale_y_reverse() +\n  coord_fixed() +\n  theme(legend.position = 'none')## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth\nnorm <- im^0.5\npar(mfrow=c(1,2))\nplot(imager::as.cimg(im), main = 'Original image')## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth\nplot(imager::as.cimg(norm), main = 'Brightened image')## Warning in as.cimg.array(norm): Assuming third dimension corresponds to time/depth\npar(mfrow=c(1,1))\n\ncellMask <- runCellSegModel( norm )\ndf <- as.data.frame(imager::as.cimg(cellMask))\nggplot() +\n  geom_raster( data = as.data.frame(imager::as.cimg(im)), \n               aes(x=x, y=y, fill=value) ) +\n  scale_fill_gradient(low='black', high='white') +\n  geom_point( data=df[df$value>0,], \n              aes(x=x, y=y, colour=factor(value)),\n              shape = '.') +\n  scale_colour_viridis_d( option='turbo' ) +\n  theme_void( base_size = 14 ) +\n  scale_y_reverse() +\n  coord_fixed() +\n  theme(legend.position = 'none')## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth\nnorm <- im^1.5\npar(mfrow=c(1,2))\nplot(imager::as.cimg(im), main = 'Original image')## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth\nplot(imager::as.cimg(norm), main = 'Darkened image')## Warning in as.cimg.array(norm): Assuming third dimension corresponds to time/depth\npar(mfrow=c(1,1))\n\ncellMask <- runCellSegModel( norm )\ndf <- as.data.frame(imager::as.cimg(cellMask))\nggplot() +\n  geom_raster( data = as.data.frame(imager::as.cimg(im)), \n               aes(x=x, y=y, fill=value) ) +\n  scale_fill_gradient(low='black', high='white') +\n  geom_point( data=df[df$value>0,], \n              aes(x=x, y=y, colour=factor(value)),\n              shape = '.') +\n  scale_colour_viridis_d( option='turbo' ) +\n  theme_void( base_size = 14 ) +\n  scale_y_reverse() +\n  coord_fixed() +\n  theme(legend.position = 'none')## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth\npowerValues <- seq(0.5, 2, length.out = 6)\npar(mfrow=c(2, 3))\nimList <- lapply( powerValues, function(x){ \n  norm <- im^x\n  plot( imager::as.cimg(norm), main = paste0('Image ^ ', round(x, digits=1) ) ) \n  return(norm)\n  })## Warning in as.cimg.array(norm): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(norm): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(norm): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(norm): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(norm): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(norm): Assuming third dimension corresponds to time/depth\nnames( imList ) <- paste0(\"Power\", round(powerValues, digits=1))\n\ncellMasks <- runCellSegModel( imList )\nfor(i in 1:length(cellMasks)){\n  plot( imager::as.cimg(cellMasks[[i]]), main = paste0('Masks of ', names(cellMasks)[i]) )\n}\npar(mfrow=c(1, 1))\ncellMask <- consolidateCellSegMasks( cellMasks )\ndf <- as.data.frame(imager::as.cimg(cellMask))\nggplot() +\n  geom_raster( data = as.data.frame(imager::as.cimg(im)), \n               aes(x=x, y=y, fill=value) ) +\n  scale_fill_gradient(low='black', high='white') +\n  geom_point( data=df[df$value>0,], \n              aes(x=x, y=y, colour=factor(value)),\n              shape = '.') +\n  scale_colour_viridis_d( option='turbo' ) +\n  theme_void( base_size = 14 ) +\n  scale_y_reverse() +\n  coord_fixed() +\n  theme(legend.position = 'none')## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth\ncellMask <- consolidateCellSegMasks( cellMasks, minFlags = 2 )\ndf <- as.data.frame(imager::as.cimg(cellMask))\nggplot() +\n  geom_raster( data = as.data.frame(imager::as.cimg(im)), \n               aes(x=x, y=y, fill=value) ) +\n  scale_fill_gradient(low='black', high='white') +\n  geom_point( data=df[df$value>0,], \n              aes(x=x, y=y, colour=factor(value)),\n              shape = '.') +\n  scale_colour_viridis_d( option='turbo' ) +\n  theme_void( base_size = 14 ) +\n  scale_y_reverse() +\n  coord_fixed() +\n  theme(legend.position = 'none')## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth"},{"path":"cell-segmentation.html","id":"saving-cell-masks","chapter":"5 Cell segmentation","heading":"5.4 Saving cell masks","text":"users satisfied model performance, can use saveCellSegMasks save masks .csv.gz file. Additionally, recommended users save DAPI image used cell segmentation. default, last image processed stored params$cell_seg_image, saved images specified saveCellSegMasks.Saving cell masks creates CELLSEG_{ Cell segmentation model }_{ FOV name }.csv.gz file containing masks, REGIM_{ FOV Name }.png image (depending input im parameter).","code":"\npar(mfrow=c(1,2))\nplot( imager::as.cimg(im), main = 'Original image' )## Warning in as.cimg.array(im): Assuming third dimension corresponds to time/depth\nplot( imager::as.cimg(params$cell_seg_image), main = 'Last image processed' )## Warning in as.cimg.array(params$cell_seg_image): Assuming third dimension corresponds to time/depth\npar(mfrow=c(1,1))\nsaveCellSegMasks(cellMask, im = im)\nfile.exists( paste0(params$out_dir, 'REGIM_', params$current_fov, '.png') )## [1] TRUE"},{"path":"stitching.html","id":"stitching","chapter":"6 Stitching","heading":"6 Stitching","text":"Stitching task aligning adjacent overlapping FOVs, obtain coherent coordinate system across FOVs. can done DAPI images, reference bit MERFISH (.e. image registration performed respect – typically first bit). can thus done parallel previous two tasks.Alternatively, recall part spotcalling (Chapter 3.4.2) cell segmentation (Chapter 5.4), reference images returned REGIM_{ FOV Name }.png. Users may wish use instead; stitching performed previous two tasks.","code":"\nlibrary(masmr)\nlibrary(ggplot2)"},{"path":"stitching.html","id":"pre-processing-3","chapter":"6 Stitching","heading":"6.1 Pre-processing","text":"Parameters established .stage, relevant metadata files (META_RESOLUTION.txt GLOBALCOORD.csv) created DAPI MERFISH data using readImageMetaData function (see previous Chapters). minimum requirement stitching {masmr}. [generated early respective pipelines.]thus two subdirectories stage, one MERFISH data one DAPI data. metadata files.","code":"\ndata_dir = 'C:/Users/kwaje/Downloads/JIN_SIM/20190718_WK_T2_a_B2_R8_12_d50/'\nestablishParams(\n  \n  ## User to fill in\n  imageDirs = paste0(data_dir, 'S10/'),\n  imageFormat = '.ome.tif',\n  outDir = 'C:/Users/kwaje/Downloads/JYOUT/',\n  codebookFileName = list.files(paste0(data_dir,'codebook/'),pattern='codebook',full.names = TRUE),\n  dapiDir = paste0(data_dir, 'DAPI_1/'),\n  \n  ## Will attempt automatic fill\n  # metaFormat = '.ome.tif',\n  # dapiFormat = '.ome.tif',\n  codebookColumnNames = paste0(rep(c(0:3),4),'_',rep(c('cy3','alexa594','cy5','cy7'),each=4)),\n  pythonLocation = 'C:/Users/kwaje/AppData/Local/miniforge3/envs/scipyenv/',\n  \n  ## Automatically filled\n  # seed = 12345,\n  verbose = FALSE,\n  # resumeMode = TRUE,\n  \n  ## Optional (but recommended for QC checks)\n  fpkmFileName = paste0(data_dir, \"FPKM_data/Jin_FPKMData_B.tsv\"),\n  nProbesFileName = paste0(data_dir, \"ProbesPerGene.csv\")\n)## Assuming .ome.tif is extension for meta files...\nlist.files( params$parent_out_dir, pattern = 'GLOBALCOORD.csv', recursive = T, full.names = T )## [1] \"C:/Users/kwaje/Downloads/JYOUT/DAPI/GLOBALCOORD.csv\" \"C:/Users/kwaje/Downloads/JYOUT/IM/GLOBALCOORD.csv\"\nlist.files( params$parent_out_dir, pattern = 'META_RESOLUTION.txt', recursive = T, full.names = T )## [1] \"C:/Users/kwaje/Downloads/JYOUT/DAPI/META_RESOLUTION.txt\" \"C:/Users/kwaje/Downloads/JYOUT/IM/META_RESOLUTION.txt\""},{"path":"stitching.html","id":"loading-images-for-stitching","chapter":"6 Stitching","heading":"6.2 Loading images for stitching","text":"stitching, need load reference FOV, FOVs immediately surrounding . instance, let’s select FOV processed previous Chapters. one GLOBALCOORD.csv files, expect load four FOVs blue , alongside reference FOV (red).actual loading accomplished readImagesForStitch function. default load MERFISH images.subDirectory parameter allows easy swapping DAPI MERFISH images.Every time readImagesForStitch run, stitchParams environment object generated. functions similarly params: houses parameters image handling file saving. also copies params$current_fov [separate params owing users possibly wishing handle MERFISH DAPI images.], apparent raw MERFISH images may require image processing prior stitching (e.g. brightening image). recommend image processing done image registration (Chapter 3.4.2).stitching done spotcalling complete FOVs, processed images reference bit accessible setting loadProcessedImages TRUE. default, loadProcessedImages parameter FALSE. TRUE, function first attempt search REGIM_{ FOV Name }.png images load instead. unable , loadProcessedImages switched back FALSE, raw images loaded instead (failure find processed images returned warning).Otherwise, can reprocess raw images specifying imageFunction parameter. [minimum maximum brightness come outputs getAnchorParams; done early spotcalling pipeline (see Chapter 3.2.2).]","code":"\nparams$current_fov <- 'MMStack_1-Pos_002_003'\ngcx <- data.table::fread( \n  list.files( params$parent_out_dir, pattern = 'GLOBALCOORD.csv', recursive = T, full.names = T )[1],\n  data.table = F\n)\ngcx <- gcx[!duplicated(gcx$fov),]\ngcx$X <- as.integer( factor(gcx$x_microns) )\ngcx$Y <- as.integer( factor(gcx$y_microns) )\ngcx$CX <- gcx$X + 1i * gcx$Y\ngcx$fov_type <- ifelse(\n  gcx$fov==params$current_fov, 'Reference', \n  ifelse(\n    Mod( gcx$CX - gcx$CX[gcx$fov==params$current_fov] ) == 1,\n    'Neighbour', 'Other'))\ngcx$short_name <- gsub('MMStack_1-Pos_|00', '', gcx$fov)\nggplot( gcx ) +\n  geom_text( aes(x=x_microns, y=y_microns, label=short_name, colour = fov_type),\n             size = 5 ) +\n  scale_colour_manual( name='', values = c('Reference' = 'red', 'Neighbour' = 'blue', 'Other' = 'black')) +\n  scale_y_reverse() + xlab('X (microns)') + ylab('Y (microns)') +\n  theme_minimal(base_size=14)\n## params$current_fov specifies which image to load\nimList <- readImagesForStitch()\npar(mfrow=c(2,3))\nfor(i in 1:length(imList)){\n  plot(imager::as.cimg(imList[[i]]), main=names(imList)[i])\n}## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\npar(mfrow = c(1,1))\nimList <- readImagesForStitch( subDirectory = 'DAPI' )\npar(mfrow=c(2,3))\nfor(i in 1:length(imList)){\n  plot(imager::as.cimg(imList[[i]]), main=names(imList)[i])\n}## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\npar(mfrow = c(1,1))\ndapiList <- imList\nls( envir = stitchParams )##  [1] \"current_fov\"             \"fov_names\"               \"fovs_loaded\"             \"global_coords\"           \"im_format\"              \n##  [6] \"out_dir\"                 \"processed_images_loaded\" \"resolutions\"             \"sub_directory\"           \"verbose\"\nimFunction <- function( im ){\n  \n  minBrightness = 0.0370383157674109 #First bit floor\n  maxBrightness = 0.288414576071673  #First bit cap\n  \n  norm <- \n    imLowPass(im, floorVal = minBrightness, ceilVal = maxBrightness) +\n    imForDecode(im, floorVal = minBrightness, ceilVal = maxBrightness)\n  norm <- imNormalise(norm)\n  \n  return( norm )\n}\n\nimList <- readImagesForStitch( subDirectory = 'IM', imageFunction = imFunction)\npar(mfrow=c(2,3))\nfor(i in 1:length(imList)){\n  plot(imager::as.cimg(imList[[i]]), main=names(imList)[i])\n}## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\n\n## Warning in as.cimg.array(imList[[i]]): Assuming third dimension corresponds to time/depth\npar(mfrow = c(1,1))\nmerList <- imList"},{"path":"stitching.html","id":"performing-stitching","chapter":"6 Stitching","heading":"6.3 Performing stitching","text":"task stitching similar image registration stitching algorithm stitchImages similarly relies cross-correlation reference image. default, first image list – also current FOV processed – used.Users may wish stitch DAPI MERFISH images compare.Stitching can evaluated visually. can obtained setting returnTroubleShootPlots stitchImages TRUE, manual use stitch_troubleshootPlots function (see documentation). reference FOV shown red, neighbour blue.","code":"\nstitchResults <- stitchImages(merList)## Warning in stitchImages(merList): Z stack detected...Defaulting to MIP...\nknitr::kable(stitchResults, format = 'html', booktabs = T)\n## Keep the old stitch vector\ndf <- stitchResults\ncolnames(df)[2] <- paste0('merfish_', colnames(stitchResults)[2])\n\n## Re-run stitching but with DAPI images\nstitchResults <- stitchImages(dapiList, returnTroubleShootPlots = TRUE) ## Warning in stitchImages(dapiList, returnTroubleShootPlots = TRUE): Z stack detected...Defaulting to MIP...\ncolnames(stitchResults)[2] <- paste0('dapi_', colnames(stitchResults)[2])\nstitchResults[,colnames(df)[2]] <- df[match(stitchResults[,1], df[,1]),2]\nknitr::kable(stitchResults, format = 'html', booktabs = T)\n## Plots are returned for each neihgbour, will show just one below\np_unstitched <- troubleshootPlots[['STITCH_EVAL']][[4]][['UNSTITCHED']]\np_stitched <- troubleshootPlots[['STITCH_EVAL']][[4]][['STITCHED']]\n\n## Re-scale alpha so that low brightness is more solid\n## We find this makes the stitch visually clearer for DAPI images\ncowplot::plot_grid( plotlist = list(\n  p_unstitched  + ggtitle('Unstitched') + scale_alpha(range=c(0.75, 0)),\n  p_stitched  + ggtitle('Stitched') + scale_alpha(range=c(0.75, 0))\n), nrow=1)"},{"path":"stitching.html","id":"saving-stitch-vectors","chapter":"6 Stitching","heading":"6.4 Saving stitch vectors","text":"Finally, users may save dataframe output using saveStitch function. strictly necessary, recommended, ensure standardised file names compatability rest {masmr}.","code":"\nsaveStitch( stitchResults )\nfile.exists( paste0(stitchParams$out_dir, 'STITCH_', stitchParams$current_fov, '.csv') )## [1] TRUE"},{"path":"synthesis.html","id":"synthesis","chapter":"7 Synthesis","heading":"7 Synthesis","text":"Synthesis involves consolidation disparate outputs final task. focus Chapter.","code":"\nlibrary(masmr)\nlibrary(ggplot2)"},{"path":"synthesis.html","id":"unifying-outputs","chapter":"7 Synthesis","heading":"7.1 Unifying outputs","text":"consequence running scripts preceding chapters, expect three subdirectories user-specified output directory: one spotcalling outputs (IM), one cell segmentation (DAPI), one stitching (STITCH). outputs three subdirectories combined, output final subdirectory.illustrative purposes, processed just nine FOVs . Also note removeRedundancy parameter currently set FALSE – explained later.files created subdirectory follows:OUT_CELLEXPRESSION.csv.gz: Gene expression per cell. [created matching spotcall cell segmentation files FOV.]OUT_CELLS.csv.gz: Cellular coordinates, sizes, metadata.OUT_CELLSEG_PIXELS.csv.gz: Concatenated cell segmentation masks across FOVs, unified coordinate system.OUT_GLOBALCOORD.csv: Updated global coordinates FOV.OUT_SPOTCALL_PIXELS.csv.gz: Concatenated spotcall dataframes across FOVs, unified coordinate system.Currently, removeRedundancy turned , dataframes simply concatenated. problematic FOVs overlap, causing spots counted . can seen FOV boundaries, higher count densities.expect cells, counts per cell.address problem, can turn removeRedundancy (TRUE default), effect :Removing redundant spots: Spots per FOV overlapping region counted. FOV contributing fewer spots overlapping region ignored.Removing redundant cells: cells different FOVs overlap <\\(X\\)%, overlapping pixels simply disregarded. However, overlap >\\(X\\)%, one cells removed. general, drop smaller cells cells overlap one cell another FOV. choice \\(X\\) depends cellOverlapFraction parameter (default 0.25, .e. 25%).Accordingly, removing duplicate calls reduces spot density FOV boundaries……reduces number cells counts per cell.One final feature consider use subsetFOV field. used FOVs disjoint, .e. connected (multiple samples microscopy stage, FOVs samples captured). cases, one needs subset just FOVs belonging one intact block.Note subsetting, subdirectories within \\created named SUBSET_{ Reference FOV } format. WARNING: assumed two subsets Reference FOV. [control folder names, users can use customOutDirName parameter synthesiseData.]Accordingly, output within subdirectory subset processed FOVs.","code":"\ndata_dir = 'C:/Users/kwaje/Downloads/JIN_SIM/20190718_WK_T2_a_B2_R8_12_d50/'\nestablishParams(\n  \n  ## User to fill in\n  imageDirs = paste0(data_dir, 'S10/'),\n  imageFormat = '.ome.tif',\n  outDir = 'C:/Users/kwaje/Downloads/JYOUT/',\n  codebookFileName = list.files(paste0(data_dir,'codebook/'),pattern='codebook',full.names = TRUE),\n  dapiDir = paste0(data_dir, 'DAPI_1/'),\n  \n  ## Will attempt automatic fill\n  # metaFormat = '.ome.tif',\n  # dapiFormat = '.ome.tif',\n  codebookColumnNames = paste0(rep(c(0:3),4),'_',rep(c('cy3','alexa594','cy5','cy7'),each=4)),\n  pythonLocation = 'C:/Users/kwaje/AppData/Local/miniforge3/envs/scipyenv/',\n  \n  ## Automatically filled\n  # seed = 12345,\n  verbose = FALSE,\n  # resumeMode = TRUE,\n  \n  ## Optional (but recommended for QC checks)\n  fpkmFileName = paste0(data_dir, \"FPKM_data/Jin_FPKMData_B.tsv\"),\n  nProbesFileName = paste0(data_dir, \"ProbesPerGene.csv\")\n)## Assuming .ome.tif is extension for meta files...\n## The synthesiseData function\nsynthesiseData(removeRedundancy = F)\nlist.files( paste0(params$parent_out_dir, '/OUT/') )## [1] \"OUT_CELLEXPRESSION.csv.gz\"  \"OUT_CELLS.csv.gz\"           \"OUT_CELLSEG_PIXELS.csv.gz\"  \"OUT_GLOBALCOORD.csv\"        \"OUT_SPOTCALL_PIXELS.csv.gz\"\nspotcalldf <- data.table::fread(paste0(params$parent_out_dir, '/OUT/OUT_SPOTCALL_PIXELS.csv.gz'), data.table = F)\ncowplot::plot_grid( plotlist=list(\n  ggplot() +\n    geom_hex(data=spotcalldf, aes(x=Xm, y=Ym), bins=100) +\n    scale_fill_viridis_c(option='turbo') +\n    scale_y_reverse() +\n    theme_minimal(base_size=14) +\n    xlab('X (microns)') + ylab('Y (microns)') +\n    theme(legend.position = 'none') +\n    coord_fixed() + \n    ggtitle('Spot density'), \n  ggplot() +\n    geom_point(data=spotcalldf, aes(x=Xm, y=Ym, colour=fov), shape='.', alpha=0.5) +\n    scale_colour_viridis_d(name = '', option='turbo') +\n    scale_y_reverse() +\n    theme_minimal(base_size=14) +\n    xlab('X (microns)') + ylab('Y (microns)') +\n    guides(colour=guide_legend(override.aes = list(size=5, shape=16), ncol=1)) +\n    coord_fixed() +\n    theme(legend.position = 'none') +\n    ggtitle('Spots by FOV')\n), nrow=1)\ncellExp <- data.table::fread(paste0(params$parent_out_dir, '/OUT/OUT_CELLEXPRESSION.csv.gz'), data.table = F)\nrownames(cellExp) <- cellExp[,1]\ncellExp[,1] <- NULL\n\nhist(log10(1+colSums(cellExp)), \n     main = paste0( \n       'Cells x genes: ', paste( dim(cellExp), collapse=' x '), \n       ', Median nCounts: ', median(colSums(cellExp))), \n     breaks=25, xlab = 'Log10 nCounts per cell'); \nabline(v=log10(1+median(colSums(cellExp))), col='red')\nsynthesiseData(removeRedundancy = T, cellOverlapFraction = 0.25)## Warning in synthesiseData(removeRedundancy = T, cellOverlapFraction = 0.25): Overwriting existing files## Warning in data.table::fwrite(data.frame(CELLNAME = unique(cellDropCheck)), : Input has no columns; creating an empty file at\n## 'C:/Users/kwaje/Downloads/JYOUT/OUT/TEMP_CELLDROP.csv' and exiting.## Warning in data.table::fwrite(data.frame(CELLNAME = unique(cellDropCheck)), : Input has no columns; doing nothing.\n## If you intended to overwrite the file at C:/Users/kwaje/Downloads/JYOUT/OUT/TEMP_CELLDROP.csv with an empty one, please use file.remove first.\nspotcalldf <- data.table::fread(paste0(params$parent_out_dir, '/OUT/OUT_SPOTCALL_PIXELS.csv.gz'), data.table = F)\ncowplot::plot_grid( plotlist=list(\n  ggplot() +\n    geom_hex(data=spotcalldf, aes(x=Xm, y=Ym), bins=100) +\n    scale_fill_viridis_c(option='turbo') +\n    scale_y_reverse() +\n    theme_minimal(base_size=14) +\n    xlab('X (microns)') + ylab('Y (microns)') +\n    theme(legend.position = 'none') +\n    coord_fixed() + \n    ggtitle('Spot density'), \n  ggplot() +\n    geom_point(data=spotcalldf, aes(x=Xm, y=Ym, colour=fov), shape='.', alpha=0.5) +\n    scale_colour_viridis_d(name = '', option='turbo') +\n    scale_y_reverse() +\n    theme_minimal(base_size=14) +\n    xlab('X (microns)') + ylab('Y (microns)') +\n    guides(colour=guide_legend(override.aes = list(size=5, shape=16), ncol=1)) +\n    coord_fixed() +\n    theme(legend.position = 'none') +\n    ggtitle('Spots by FOV')\n), nrow=1)\ncellExp <- data.table::fread(paste0(params$parent_out_dir, '/OUT/OUT_CELLEXPRESSION.csv.gz'), data.table = F)\nrownames(cellExp) <- cellExp[,1]\ncellExp[,1] <- NULL\n\nhist(log10(1+colSums(cellExp)), \n     main = paste0( \n       'Cells x genes: ', paste( dim(cellExp), collapse=' x '), \n       ', Median nCounts: ', median(colSums(cellExp))), \n     breaks=25, xlab = 'Log10 nCounts per cell'); \nabline(v=log10(1+median(colSums(cellExp))), col='red')\nfovs_belonging_to_sample <- c(\n  'MMStack_1-Pos_002_004',\n  'MMStack_1-Pos_002_002',\n  'MMStack_1-Pos_002_003'\n)\nsynthesiseData(removeRedundancy = T, cellOverlapFraction = 0.25, subsetFOV = fovs_belonging_to_sample)\nprint( params$out_dir )## [1] \"C:/Users/kwaje/Downloads/JYOUT/OUT/SUBSET_MMStack_1-Pos_002_002/\"\nspotcalldf <- data.table::fread(paste0(params$out_dir, '/OUT_SPOTCALL_PIXELS.csv.gz'), data.table = F)\ncowplot::plot_grid( plotlist=list(\n  ggplot() +\n    geom_hex(data=spotcalldf, aes(x=Xm, y=Ym), bins=100) +\n    scale_fill_viridis_c(option='turbo') +\n    scale_y_reverse() +\n    theme_minimal(base_size=14) +\n    xlab('X (microns)') + ylab('Y (microns)') +\n    theme(legend.position = 'none') +\n    coord_fixed() + \n    ggtitle('Spot density'), \n  ggplot() +\n    geom_point(data=spotcalldf, aes(x=Xm, y=Ym, colour=fov), shape='.', alpha=0.5) +\n    scale_colour_viridis_d(name = '', option='turbo') +\n    scale_y_reverse() +\n    theme_minimal(base_size=14) +\n    xlab('X (microns)') + ylab('Y (microns)') +\n    guides(colour=guide_legend(override.aes = list(size=5, shape=16), ncol=1)) +\n    coord_fixed() +\n    theme(legend.position = 'none') +\n    ggtitle('Spots by FOV')\n), nrow=1)"},{"path":"synthesis.html","id":"qc-plotting","chapter":"7 Synthesis","heading":"7.2 QC plotting","text":"provided plotQC function returns several default QC plots .png files. function depends parameters input establishParams: e.g. fpkmFileName missing, FPKM correlations plotted. Additionally, users ran prepareCodebook exhaustiveBlanks, newly added blanks flagged. [Users wishing ignore new blanks can set includeNewBlanks plotQC FALSE (see ).]interpretation plots covered briefly .","code":"\nplotQC( \n  includeNewBlanks=T,\n  synthesisDir = 'C:/Users/kwaje/Downloads/JYOUT/OUT/' #To refer to previously generated (un-subset) output\n  )"},{"path":"synthesis.html","id":"fpkmcorrelation","chapter":"7 Synthesis","heading":"FPKMCorrelation","text":"plot returns correlation expected expression number spots actually observed (bot log-transformed); strong correlations ideal. title plot, also report percentage spots blanks (specifically blank names), percentage spots overlap cell mask.","code":""},{"path":"synthesis.html","id":"cosinedistancedistribution","chapter":"7 Synthesis","heading":"CosineDistanceDistribution","text":"shows distribution cosine distances (COS) per gene. Lower cosine distances implies higher confidence decoding spot.","code":""},{"path":"synthesis.html","id":"spotfovdistribution","chapter":"7 Synthesis","heading":"SpotFOVDistribution","text":"shows distribution spots, averaged across FOVs. used check spot coordinate given FOV influences detection rate – ideally, occur. e.g. spots frequently detected centre FOV edges, suggest uneven lighting need correct image processing. [plot less useful handful FOVs processed.]Note plot created SPOTCALL files, without removing redundant spots.","code":""},{"path":"synthesis.html","id":"cosinespatialdistribution","chapter":"7 Synthesis","heading":"CosineSpatialDistribution","text":"plot shows average cosine distances per 2D bin, across entire tissue. Ideally, spatial location influence confidence spot calls.Note – like SpotFOVDistribution – plot created SPOTCALL files, without removing redundant spots.","code":""},{"path":"synthesis.html","id":"bitdetectionrate","chapter":"7 Synthesis","heading":"BitDetectionRate","text":"shows / status bit influences number spots called. tabulate number spots per gene, split genes two groups bit: (1), (0). provides indication whether separation 0 vs 1 clearer / ambiguous certain bits. Ideally, obvious bias detection rate bits.shows , time spots non-blanks (BitDetectionRateNonBlank.png, instead BitDetectionRateAll.png).","code":""},{"path":"synthesis.html","id":"bitwiseerrorrates","chapter":"7 Synthesis","heading":"BitwiseErrorRates","text":"barplot shows percentage errors every bit. reported bitsFromDecode run spotcalling.(Chen et al. 2015), error rate expected 10%, 4%. course, might vary depending data set choice hyperparameters decoding.","code":""},{"path":"synthesis.html","id":"fovmetrics","chapter":"7 Synthesis","heading":"FOVMetrics","text":"shows statistics averaged per FOV. Useful determining systematic failures spot calling certain FOVs.","code":""},{"path":"synthesis.html","id":"cellmetrics","chapter":"7 Synthesis","heading":"CellMetrics","text":"shows cell-wise metrics. , show average cell size (pixels) per 2D bin.shows average number spots per 2D bin.","code":""},{"path":"synthesis.html","id":"spatialpatterns","chapter":"7 Synthesis","heading":"SpatialPatterns","text":"comprises two related plots. first comprises SpatialPatterns . default, typically return four fewer spatial patterns.second GeneMembership, used determine much spatial pattern contributes given gene’s expression pattern.plots provide quick way users determine genes adopting spatial patterns expression matches expectations.also acknowledge analysis may applications beyond QC. users wishing tune analysis downstream use (e.g. including /fewer factors etc), now explain plots generated hood.","code":""},{"path":"synthesis.html","id":"explaining-how-spatial-patterns-were-identified","chapter":"7 Synthesis","heading":"7.3 Explaining how spatial patterns were identified","text":"first generate table indicating often given gene X neighbour gene Y. several ways ; found fast scaleable solution creating graph spots Delaunay triangulation, scanning neighbours increasing degrees. spot belonging gene X, calculate often neighbour gene Y. [first degree neighbour spot immediately connected reference spot graph. Second degree neighbours connected first degree etc.]Users may alternatively, simultaneously, wish consider physical Euclidean distances (.e. genes within 5 microns coordinate, within 10 microns etc). method typically slower memory intensive.can accomplished getPNNMatrix function (PNN stands “Point’s Nearest Neighbour”).[Note: run inside plotQC, output getPNNMatrix saved .csv file.]end product table spots rows, often gene Y neighbour given distance columns. table many uses: e.g. users can look see probability gene X neighbour gene Y changes distance. plots, use matrix cluster genes spatial patterns.[Note: getPNNMatrix just confined looking spatial patterns genes, can applied point data (e.g. cell coordinates cell types).]Clustering accomplished non-negative matrix factorization (NMF). number ‘clusters’ (aka ‘factors’) defined user. choose appropriate number factors personal decision, literature provides helpful guidelines:Estimate number Principle Components explain X% variance data (use elbow plot).Try different numbers factors find elbow reduction residuals (e.g. sum squared error) plateaus.[Note: chose NMF speed RcppML package. Users may also explore approaches clustering: e.g. hierarchical clustering, leiden etc.], users can use getPNNLatentFactors function. function runs NMF, also merges similar factors together (based Pearson correlation threshold indicated correlationThreshold).returned list three objects:n_factors: number factors (merging, merging occured).point_scores: “score” row nearestNeighbourMatrix (.e. spot) factors (aka W matrix). undergone min-max scaling per factor.coefficients: “score” column nearestNeighbourMatrix factors (aka H matrix). undergone min-max scaling per factor.point_scores relevant , can appended spotcalldf tell us score spot – plot SpatialPatterns (averaging 2D bins) GeneMembership (averaging per gene).[Note: getPNNLatentFactors can actually applied non-negative matrix, just one returned getPNNMatrix.]","code":"\nnearestNeighbourMatrix <- getPNNMatrix(\n  \n  x = spotcalldf$Xm, # The x coordinate\n  y = spotcalldf$Ym, # The y coordinate\n  label = spotcalldf$g, # The category that a given spot belongs to\n  \n  delaunayTriangulation = T, # Whether to use Delaunay Triangulation approach\n  delaunayDistanceThreshold = 20, # Ignore links longer than this distance (Xm is in microns, so this is 20 microns) \n  delaunayNNDegrees = c(1:3), # Consider 1st, 1st + 2nd, and 1st + 2nd + 3rd order neighbours\n  \n  euclideanDistances = c(5, 10), # Consider spots <5, and <10 microns away\n  verbose = F # Turn off messages\n)\nprint( paste0('Dimensions of nearest neighbour matrix: ', paste(dim(nearestNeighbourMatrix), collapse = ' x ') ))## [1] \"Dimensions of nearest neighbour matrix: 13145 x 735\"\nknitr::kable( nearestNeighbourMatrix[1:5, 1:5], format = 'html', booktabs = TRUE )\nresultsOfNMF <- getPNNLatentFactors(\n  nearestNeighbourMatrix,\n  nFactors = 4, #Number of factors specified here\n  mergeSimilarFactors = TRUE,\n  correlationThreshold = 0.1, #If correlation >0.1 in W matrix ('point_scores'), merge\n  verbose = F\n)\nprint( names(resultsOfNMF) )## [1] \"n_factors\"    \"point_scores\" \"coefficients\""},{"path":"synthesis.html","id":"next-steps","chapter":"7 Synthesis","heading":"7.4 Next steps","text":"Yay! MERFISH pipeline now done. satisfied results, downstream analysis can done OUT_CELLEXPRESSION.csv.gz matrix – contains cell-wise gene expression – using standard single cell RNA-sequencing pipelines. [advanced bioinformaticians may wish perform custom analysis address e.g. lower counts per cell spatial technologies (violates assumptions normalisation algorithms used scRNA-seq).]unsatisfied, users can go back re-process data tweaked parameters. Suggestions troubleshooting provided next chapter.","code":""},{"path":"troubleshooting.html","id":"troubleshooting","chapter":"8 Troubleshooting","heading":"8 Troubleshooting","text":"{masmr} package designed enable users build custom pipelines. Users encouraged play around FOV two, determine optimal parameter choices, looping entire data set., provide suggestions users seeking improve pipelines. organised potential problems, possible causes (identify ), potential solutions.","code":""},{"path":"troubleshooting.html","id":"too-few-spots","chapter":"8 Troubleshooting","heading":"Too few spots","text":"Poor choice image processing. best identified spotcalling script , rather synthesis step end. Users encouraged plot processed images using plot(imager::.cimg( imageMatrix )). [.cimg offers considerable speed .] Users may attempt manual decoding small region one two FOVs (.e. look images determine sequence pixel /), ensure pipeline returns results agree manual decoding. pipeline – optimised subset FOVs – can looped FOVs apply consistent spotcalling standards.\nPotential solution: Changing function used return MASK getImageMetrics. Larger masks means pixels brought forwards subsequent decoding.\nPotential solution: Changing function used return DECODE getImageMetrics. far possible, attempt return bimodal distribution clear separation bits intensity.\nPotential solution: Changing function used return MASK getImageMetrics. Larger masks means pixels brought forwards subsequent decoding.Potential solution: Changing function used return DECODE getImageMetrics. far possible, attempt return bimodal distribution clear separation bits intensity.Filtering criteria strict. also best identified spotcalling script . Users encouraged use filterDF function keep track spot profiles per FOV changing filter step.\nPotential solution: add blanks prepareCodebook – .e. set exhaustiveBlanks = F – increase strictness criteria calling blanks scoreBlanks. many subsequent steps rely blank detection: blanks likely increases strictness filtering pixels.\nPotential solution: bitsFromDecode, swapping default f1 fb allows users upweight / downweight recall respect precision using fBeta. E.g. fBeta >1 upweights recall minimises false negatives. Alternatively, users may skip bitsFromDecode entirely (though recommended).\nPotential solution: filtering thresh_Quantile, consider tuning quantileFalse quantileTrue. E.g. labels vector pixel blank TRUE, metric vector probability blank (e.g. returned scoreClassifier), decreasing quantileTrue default 0.5 0.25 increases tolerance keeping blanks. [direction move quantileFalse quantileTrue depends metric question, labels coded.]\nPotential solution: Reduce number filtering steps. perhaps best done several steps may redundant given later filtering: e.g. filtering using DFF0 metrics may redundant later scoreClassifier step uses DFF0 covariate.\nPotential solution: Increase maxInterSpotDistancePixels spatialClusterLeiden distal spots considered per cluster. [general, larger impact filtering using HNN distances – similarly removes loner spots (though can tweaked).] Alternatively, users also reduce minimum number pixels required per cluster (default = 3).\nPotential solution: add blanks prepareCodebook – .e. set exhaustiveBlanks = F – increase strictness criteria calling blanks scoreBlanks. many subsequent steps rely blank detection: blanks likely increases strictness filtering pixels.Potential solution: bitsFromDecode, swapping default f1 fb allows users upweight / downweight recall respect precision using fBeta. E.g. fBeta >1 upweights recall minimises false negatives. Alternatively, users may skip bitsFromDecode entirely (though recommended).Potential solution: filtering thresh_Quantile, consider tuning quantileFalse quantileTrue. E.g. labels vector pixel blank TRUE, metric vector probability blank (e.g. returned scoreClassifier), decreasing quantileTrue default 0.5 0.25 increases tolerance keeping blanks. [direction move quantileFalse quantileTrue depends metric question, labels coded.]Potential solution: Reduce number filtering steps. perhaps best done several steps may redundant given later filtering: e.g. filtering using DFF0 metrics may redundant later scoreClassifier step uses DFF0 covariate.Potential solution: Increase maxInterSpotDistancePixels spatialClusterLeiden distal spots considered per cluster. [general, larger impact filtering using HNN distances – similarly removes loner spots (though can tweaked).] Alternatively, users also reduce minimum number pixels required per cluster (default = 3).","code":""},{"path":"troubleshooting.html","id":"too-few-cellular-spots","chapter":"8 Troubleshooting","heading":"Too few cellular spots","text":"See recommendations “spots”.See recommendations “spots”.cell masks returned cell segmentation. can evaluated CellMetrics plots, percent counts deemed cellular FPKMCorrelation. Users also plot cell masks chosen FOV.\nPotential solution: cellpose, retrain models relax cell segmentation parameters.\nPotential solution: stardist – returns masks faster cellpose – input variously brightened images consolidate cell masks using consolidateCellSegMasks. Cell segmentation parameters can also relaxed stardist, brightness seems larger contributor detection rate.\ncell masks returned cell segmentation. can evaluated CellMetrics plots, percent counts deemed cellular FPKMCorrelation. Users also plot cell masks chosen FOV.Potential solution: cellpose, retrain models relax cell segmentation parameters.Potential solution: stardist – returns masks faster cellpose – input variously brightened images consolidate cell masks using consolidateCellSegMasks. Cell segmentation parameters can also relaxed stardist, brightness seems larger contributor detection rate.Cells small. scenario, expect low percent counts deemed cellular FPKMCorrelation, despite sufficient numbers cells per unit area.\nPotential solution: Retrain cellpose models return larger masks. Run cellpose different diameter parameters, consolidate consolidateCellSegMasks.\nPotential solution: Dilate existing masks prior saving using imager::dilate_square(cellMask, X). [X least 3 isotropic dilation 1 pixel.] works cell segmentation models.\nPotential solution: Instead dilating cells, non-cellular spots may assigned cell centroids proximity. Functionally similar dilating cell masks.\nCells small. scenario, expect low percent counts deemed cellular FPKMCorrelation, despite sufficient numbers cells per unit area.Potential solution: Retrain cellpose models return larger masks. Run cellpose different diameter parameters, consolidate consolidateCellSegMasks.Potential solution: Dilate existing masks prior saving using imager::dilate_square(cellMask, X). [X least 3 isotropic dilation 1 pixel.] works cell segmentation models.Potential solution: Instead dilating cells, non-cellular spots may assigned cell centroids proximity. Functionally similar dilating cell masks.","code":""},{"path":"troubleshooting.html","id":"weak-correlation-to-fpkm-high-blank","chapter":"8 Troubleshooting","heading":"Weak correlation to FPKM / high blank %","text":"Suggests high false positive rate. opposite recommendations “spots”: .e. increase strictness filtering criteria. possible, users may attempt manual decoding small region one two FOVs, ensure pipeline returns similar results: make use troubleshoot plots returned filterDF.Suggests high false positive rate. opposite recommendations “spots”: .e. increase strictness filtering criteria. possible, users may attempt manual decoding small region one two FOVs, ensure pipeline returns similar results: make use troubleshoot plots returned filterDF.Bit-specific differences detection rate. can evaluated BitwiseErrorRates BitDetectionRate plots synthesis. [may also cause spots returned – general, tends variation across genes: genes , abundant.]\nPotential solution: Ensure getAnchorParams returning reasonable intensity ceilings floors bit. Users use empty FOVs anchor FOVs.\nPotential solution: Sometimes, bit-specific differences may expected uneven representation counts across bits (e.g. abundant genes first bit, rare genes ). [best avoided data acquisition: ensuring even bit representation designing probe library.] Users may need custom image processing per bit (opposed looping consistent function across bits).\nBit-specific differences detection rate. can evaluated BitwiseErrorRates BitDetectionRate plots synthesis. [may also cause spots returned – general, tends variation across genes: genes , abundant.]Potential solution: Ensure getAnchorParams returning reasonable intensity ceilings floors bit. Users use empty FOVs anchor FOVs.Potential solution: Sometimes, bit-specific differences may expected uneven representation counts across bits (e.g. abundant genes first bit, rare genes ). [best avoided data acquisition: ensuring even bit representation designing probe library.] Users may need custom image processing per bit (opposed looping consistent function across bits).","code":""},{"path":"troubleshooting.html","id":"issues-with-image-handling","chapter":"8 Troubleshooting","heading":"Issues with image handling","text":"java.lang.OutOfMemoryError. likely flagged reading images spotcalling, may crop cell segmentation. error accompanies RBioFormats package; loading .dax files uses inbuilt readBin function R thus return error.\nPotential solution: Increasing memory prior running scripts options(java.parameters = \"-Xmx8g\").\nPotential solution: Unloading RBioFormats unloadNamespace(RBioFormats) every often, avoid attaching loading package (e.g. library(RBioFormats)).\nPotential solution: Ensure images loaded one one (done specifying series parameter). Also ideally load images one channel slice time (done including subset = list() parameter). [Details can found Chapter spotcalling, documentation RBioFormats::read.image() masmr::readImage.] worst case, images can loaded memory tiles (subsetting x y) better memory management.\nPotential solution: Increasing memory prior running scripts options(java.parameters = \"-Xmx8g\").Potential solution: Unloading RBioFormats unloadNamespace(RBioFormats) every often, avoid attaching loading package (e.g. library(RBioFormats)).Potential solution: Ensure images loaded one one (done specifying series parameter). Also ideally load images one channel slice time (done including subset = list() parameter). [Details can found Chapter spotcalling, documentation RBioFormats::read.image() masmr::readImage.] worst case, images can loaded memory tiles (subsetting x y) better memory management.Images look like noise loaded. expect likely .dax images may due incorrect image size input, incorrect endian-ness (default: little). Alternatively, user attempted load 3D image stack 2D image – cause problems regardless image file format.\nPotential solution: Hard code image sizes specifying nrows ncols readImage/readImageList. Similarly, set endian big needed (depends instrument, recorded image metadata files).\nPotential solution: less likely alternative reason wrong number bytes assigned element .dax file. default 2 (16 bit integers); reduced 1 data saved integer value 0 255 (.e. 8 bit integer). [microscopes longer use 8 bit integers.]\nPotential solution: Hard code image sizes specifying nrows ncols readImage/readImageList. Similarly, set endian big needed (depends instrument, recorded image metadata files).Potential solution: less likely alternative reason wrong number bytes assigned element .dax file. default 2 (16 bit integers); reduced 1 data saved integer value 0 255 (.e. 8 bit integer). [microscopes longer use 8 bit integers.]Wanting work individual Z slices. various reasons (e.g. Z slice distances large, desiring high resolution spot localisation etc), users may wish process individual Z slices rather relying default maximum intensity projection (MIP).\nPotential solution: Z slices can loaded one time specifying zIndex readImage/readImageList. getAnchorParams – aims find reasonable thresholds across multiple FOVs – imageFunctions modified avoid MIP pre-processing step, instead specific Z slice loaded (example code provided ). registerImages chosenZslice parameter allows users specify specific Z slice perform registration (said, MIP still optimal position shifts affect whole Z stack, just single Z slice). Downstream functions (e.g. getImageMetrics, consolidateImageMetrics, functions work spotcalldf rather images) affected can remain unaltered.\nPotential solution: Z slices can loaded one time specifying zIndex readImage/readImageList. getAnchorParams – aims find reasonable thresholds across multiple FOVs – imageFunctions modified avoid MIP pre-processing step, instead specific Z slice loaded (example code provided ). registerImages chosenZslice parameter allows users specify specific Z slice perform registration (said, MIP still optimal position shifts affect whole Z stack, just single Z slice). Downstream functions (e.g. getImageMetrics, consolidateImageMetrics, functions work spotcalldf rather images) affected can remain unaltered.example create function returns brightness floor single Z slice, input imageFunctions getAnchorParams:","code":"## This function is looped across FOVs\n## Its input is an image / image stack called im\n## The ellipsis is used in R to allow your function to take in more unnamed parameters\nimsBrightnessMin_OneZSlice <- function( im, userChosenZSlice = 1, ... ){\n  \n  ## Check that image is indeed a stack\n  if( length(dim(im)) > 2 ){\n    ## If yes, subset the chosen zSlice\n    im <- im[,,userChosenZSlice]\n  }\n  \n  ## Make use of the default way of getting minimum brightness\n  ## Note that parameters specified by ellipsis are fed forwards into this function\n  result <- imsBrightnessMin(im, ...)\n  return(result)\n}\n\n## Do the same for max brightness, and input your new functions into getAnchorParams\nzi = 1 # The first z Slice = 1, second = 2 etc\ngetAnchorParams(\n  out_dir = paste0(params$out_dir, 'ZSlice', zi, '/') #Save results in its own folder\n  imageFunctions = list(\n    'brightness_min' = imsBrightnessMin_OneZSlice,\n    'brightness_max' = imsBrightnessMax_OneZSlice\n  ),\n  userChosenZSlice = zi #Parameters for your image function can be fed from getAnchorParams itself\n)"}]
